# ğŸ§° RAGKIT Desktop â€” SpÃ©cifications Ã‰tape 2 : Chunking

> **Ã‰tape** : 2 â€” Chunking  
> **Tag cible** : `v0.3.0`  
> **Date** : 16 fÃ©vrier 2026  
> **DÃ©pÃ´t** : https://github.com/henribesnard/ragkit_desktop.git  
> **PrÃ©requis** : Ã‰tape 1 (Ingestion & PrÃ©processing) implÃ©mentÃ©e et validÃ©e

---

## 1. Objectif

Ajouter le **dÃ©coupage intelligent des documents en chunks**, paramÃ©trable selon la stratÃ©gie dÃ©terminÃ©e lors du profilage initial (Ã‰tape 1). Le chunking est la brique qui transforme les documents bruts parsÃ©s en unitÃ©s de texte exploitables par les Ã©tapes suivantes (embedding, stockage vectoriel, recherche).

Cette Ã©tape livre :
- Une section `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > CHUNKING` complÃ¨te et fonctionnelle.
- **6 stratÃ©gies de chunking** implÃ©mentÃ©es : `fixed_size`, `sentence_based`, `paragraph_based`, `semantic`, `recursive`, `markdown_header`.
- Un **panneau de prÃ©visualisation** permettant de tester le dÃ©coupage sur un document-Ã©chantillon en temps rÃ©el.
- Le **pipeline interne parsing â†’ chunking** fonctionnel de bout en bout.
- Les **statistiques de chunking** visibles dans l'interface (nombre de chunks, tailles, distribution).

**L'embedding, le stockage vectoriel et l'indexation ne sont pas encore implÃ©mentÃ©s.** Le chunking s'exÃ©cute pour la prÃ©visualisation et la validation, mais les chunks ne sont pas encore vectorisÃ©s ni persistÃ©s dans une base vectorielle.

---

## 2. SpÃ©cifications fonctionnelles

### 2.1 Section PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > CHUNKING

#### Structure de l'onglet PARAMÃˆTRES Ã  cette Ã©tape

```
PARAMÃˆTRES
â”œâ”€â”€ ParamÃ¨tres gÃ©nÃ©raux              â† (vide pour l'instant)
â””â”€â”€ ParamÃ¨tres avancÃ©s
    â”œâ”€â”€ INGESTION & PRÃ‰PROCESSING    â† Ã‰tape 1
    â””â”€â”€ CHUNKING                     â† NOUVEAU
```

Lorsque l'utilisateur accÃ¨de Ã  `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s`, il voit maintenant deux sections dans la liste de gauche : **INGESTION & PRÃ‰PROCESSING** et **CHUNKING**. Un clic sur CHUNKING affiche le panneau dÃ©crit ci-dessous.

#### Layout de la section CHUNKING

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CHUNKING                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ StratÃ©gie de dÃ©coupage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  StratÃ©gie :           [â–¾ recursive            ]          â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â„¹ï¸ DÃ©coupe rÃ©cursivement avec une liste ordonnÃ©e de      â”‚ â”‚
â”‚  â”‚  sÃ©parateurs. RecommandÃ© pour la documentation structurÃ©e. â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ ParamÃ¨tres de taille â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Taille des chunks :   [====â—†========] 512 tokens         â”‚ â”‚
â”‚  â”‚  Chevauchement :       [==â—†==========] 100 tokens         â”‚ â”‚
â”‚  â”‚  Taille minimale :     [â—†============]  50 tokens         â”‚ â”‚
â”‚  â”‚  Taille maximale :     [==========â—†==] 2000 tokens        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Options avancÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  â˜‘ PrÃ©server les phrases (ne pas couper en milieu)        â”‚ â”‚
â”‚  â”‚  â˜‘ Propager les mÃ©tadonnÃ©es du document parent            â”‚ â”‚
â”‚  â”‚  â˜‘ Ajouter l'index du chunk                               â”‚ â”‚
â”‚  â”‚  â˜‘ Ajouter le titre du document                           â”‚ â”‚
â”‚  â”‚  â˜ Conserver les sÃ©parateurs                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ SÃ©parateurs (stratÃ©gie rÃ©cursive) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SÃ©parateurs :  ["\n\n", "\n", ". ", " "]                 â”‚ â”‚
â”‚  â”‚  [+ Ajouter]  [â†» RÃ©initialiser]                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â–¸ Chunking sÃ©mantique (affichÃ© si stratÃ©gie = semantic)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Seuil de similaritÃ© :  [=====â—†====] 0.75                â”‚ â”‚
â”‚  â”‚  Niveaux de titres :    [â–¾ 1, 2, 3           ]           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ PrÃ©visualisation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Document-Ã©chantillon : [â–¾ contrat_2024.pdf    ] [ğŸ”„]     â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  [â–¶ PrÃ©visualiser le chunking]                            â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€ RÃ©sultat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  ğŸ“Š 42 chunks Â· Moy: 487 tokens Â· Min: 52 Â· Max: 512â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€ Chunk 1/42 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 512 tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ **Source**: contrat_2024.pdf Â· **Page**: 1     â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                               â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Article 1 â€” Objet du contrat                  â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Le prÃ©sent contrat a pour objet de dÃ©finir    â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ les conditions dans lesquelles le Prestataire â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ s'engage Ã  fournir les services dÃ©crits...    â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€ Chunk 2/42 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 498 tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ **Source**: contrat_2024.pdf Â· **Page**: 1-2   â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                               â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ ...les services dÃ©crits en Annexe A.          â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                               â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Article 2 â€” DurÃ©e                             â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Le contrat est conclu pour une durÃ©e de...    â”‚  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  [â† PrÃ©cÃ©dent]  Chunk 1-2 / 42  [Suivant â†’]        â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Distribution des tailles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  â–â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–   Histogramme des tailles de chunks           â”‚ â”‚
â”‚  â”‚  50  256  512  768  1024  tokens                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  [â†» RÃ©initialiser au profil]                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Affichage conditionnel des paramÃ¨tres selon la stratÃ©gie

Certains paramÃ¨tres ne sont pertinents que pour certaines stratÃ©gies. L'interface masque dynamiquement les sections non applicables :

| ParamÃ¨tre / Section | `fixed_size` | `sentence_based` | `paragraph_based` | `semantic` | `recursive` | `markdown_header` |
|---------------------|:---:|:---:|:---:|:---:|:---:|:---:|
| Taille des chunks | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ |
| Chevauchement | âœ… | âœ… | âœ… | âœ… | âœ… | âŒ |
| Taille minimale | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| Taille maximale | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| PrÃ©server les phrases | âœ… | âŒ (toujours vrai) | âŒ (toujours vrai) | âŒ | âœ… | âŒ |
| SÃ©parateurs | âŒ | âŒ | âŒ | âŒ | âœ… | âŒ |
| Conserver sÃ©parateurs | âŒ | âŒ | âŒ | âŒ | âœ… | âŒ |
| Seuil similaritÃ© sÃ©mantique | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ |
| Niveaux de titres | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… |

**Comportements** :
- Quand l'utilisateur change de stratÃ©gie, les sections non pertinentes s'animent en fondu sortant et les sections pertinentes en fondu entrant.
- Les paramÃ¨tres masquÃ©s conservent leur valeur en mÃ©moire (pas de rÃ©initialisation au changement de stratÃ©gie).
- Un encadrÃ© informatif â„¹ï¸ sous le sÃ©lecteur de stratÃ©gie affiche une description courte de la stratÃ©gie sÃ©lectionnÃ©e (voir section 2.3).

### 2.3 Descriptions des stratÃ©gies de chunking

Chaque stratÃ©gie dispose d'une description affichÃ©e sous le sÃ©lecteur :

| StratÃ©gie | Description (FR) | Description (EN) |
|-----------|-----------------|-----------------|
| `fixed_size` | DÃ©coupe le texte en blocs de taille fixe (en tokens). Simple et prÃ©visible. | Splits text into fixed-size blocks (in tokens). Simple and predictable. |
| `sentence_based` | Regroupe des phrases complÃ¨tes jusqu'Ã  atteindre la taille cible. Respecte les frontiÃ¨res de phrases. | Groups complete sentences until reaching the target size. Respects sentence boundaries. |
| `paragraph_based` | DÃ©coupe au niveau des paragraphes. IdÃ©al pour des FAQ ou du contenu structurÃ© en blocs courts. | Splits at paragraph level. Ideal for FAQs or content structured in short blocks. |
| `semantic` | DÃ©coupe quand le sujet change, en mesurant la similaritÃ© sÃ©mantique entre phrases adjacentes. Plus lent mais plus intelligent. | Splits when the topic changes, by measuring semantic similarity between adjacent sentences. Slower but smarter. |
| `recursive` | DÃ©coupe rÃ©cursivement avec une liste ordonnÃ©e de sÃ©parateurs (paragraphes, lignes, phrases, mots). RecommandÃ© pour la documentation structurÃ©e. | Recursively splits using an ordered list of separators (paragraphs, lines, sentences, words). Recommended for structured documentation. |
| `markdown_header` | DÃ©coupe selon la hiÃ©rarchie des titres Markdown (# ## ###). IdÃ©al pour les fichiers .md ou les documents avec des titres bien dÃ©tectÃ©s. | Splits according to Markdown heading hierarchy (# ## ###). Ideal for .md files or documents with well-detected headings. |

### 2.4 Panneau de prÃ©visualisation

Le panneau de prÃ©visualisation est la fonctionnalitÃ© clÃ© de cette Ã©tape. Il permet Ã  l'utilisateur de voir concrÃ¨tement l'effet de ses paramÃ¨tres de chunking sur un document rÃ©el.

**Fonctionnement** :

1. **SÃ©lection du document-Ã©chantillon** : dropdown listant tous les documents dÃ©tectÃ©s Ã  l'Ã‰tape 1 (issus de `/api/ingestion/documents`). Le premier document de la liste est sÃ©lectionnÃ© par dÃ©faut.
2. **Bouton "PrÃ©visualiser le chunking"** : lance le processus de chunking sur le document sÃ©lectionnÃ© avec les paramÃ¨tres courants. Le bouton affiche un spinner pendant l'exÃ©cution.
3. **Barre de statistiques** : affichÃ©e immÃ©diatement aprÃ¨s le chunking :
   - Nombre total de chunks
   - Taille moyenne en tokens
   - Taille min et max
4. **Liste paginÃ©e des chunks** : affichage de 2 chunks Ã  la fois avec navigation (PrÃ©cÃ©dent / Suivant). Chaque chunk affiche :
   - Son index (ex : `Chunk 1/42`)
   - Sa taille en tokens
   - Les mÃ©tadonnÃ©es propagÃ©es (source, page, titre du document)
   - La zone de chevauchement surlignÃ©e en jaune pÃ¢le (si `chunk_overlap > 0`)
   - Le contenu textuel du chunk (tronquÃ© Ã  500 caractÃ¨res avec "â€¦" si plus long, clic pour dÃ©plier)
5. **Histogramme de distribution** : graphique en barres montrant la distribution des tailles de chunks (par tranches de 50 tokens). Permet de dÃ©tecter visuellement des anomalies (trop de micro-chunks, distribution bimodale, etc.).

**Comportements** :
- Le bouton de rafraÃ®chissement ğŸ”„ Ã  cÃ´tÃ© du sÃ©lecteur de document recharge la liste des documents (utile si la config source a changÃ©).
- La prÃ©visualisation n'est **pas automatique** au changement de paramÃ¨tre â€” l'utilisateur doit cliquer sur "PrÃ©visualiser" explicitement (pour Ã©viter des recalculs coÃ»teux en boucle, surtout avec la stratÃ©gie `semantic`).
- Si le document sÃ©lectionnÃ© contient plus de 200 chunks, un avertissement s'affiche : "Ce document produit beaucoup de chunks (N). VÃ©rifiez vos paramÃ¨tres de taille."
- Si aucun document n'est disponible (pas encore d'analyse Ã‰tape 1), un message invite l'utilisateur Ã  complÃ©ter l'Ã‰tape 1 d'abord.
- Si la stratÃ©gie `semantic` est sÃ©lectionnÃ©e mais qu'aucun modÃ¨le d'embedding n'est configurÃ© (Ã‰tape 3 pas encore faite), un avertissement s'affiche : "La stratÃ©gie sÃ©mantique nÃ©cessite un modÃ¨le d'embedding. Un modÃ¨le lÃ©ger intÃ©grÃ© sera utilisÃ© pour la prÃ©visualisation." Le backend utilise alors un modÃ¨le embarquÃ© lÃ©ger (ex : `all-MiniLM-L6-v2` via sentence-transformers) uniquement pour la prÃ©visualisation.

### 2.5 Zone de chevauchement (overlap)

Dans la prÃ©visualisation, la zone de chevauchement entre deux chunks consÃ©cutifs est identifiÃ©e visuellement :
- Le texte commun entre le chunk N et le chunk N+1 est surlignÃ© en **jaune pÃ¢le** (`bg-amber-50` en thÃ¨me clair, `bg-amber-900/20` en thÃ¨me sombre).
- Un label discret "â†” Chevauchement : 100 tokens" est affichÃ© en dessous de la zone surlignÃ©e.
- Cela permet Ã  l'utilisateur de vÃ©rifier que le chevauchement est suffisant pour ne pas perdre de contexte aux frontiÃ¨res.

### 2.6 Bouton "RÃ©initialiser au profil"

En bas de la section CHUNKING, un bouton "â†» RÃ©initialiser au profil" restaure tous les paramÃ¨tres de chunking Ã  leurs valeurs par dÃ©faut calculÃ©es par le wizard (profil + modificateurs de calibrage). L'action demande confirmation via une modale :

> âš ï¸ RÃ©initialiser les paramÃ¨tres de chunking aux valeurs du profil Â« Juridique / RÃ©glementaire Â» ? Les modifications manuelles seront perdues.

### 2.7 Badge "ModifiÃ©"

Comme pour l'Ã‰tape 1, chaque paramÃ¨tre dont la valeur diffÃ¨re de la valeur par dÃ©faut du profil affiche un badge ğŸ”µ "ModifiÃ©" Ã  cÃ´tÃ© du label. Cela permet Ã  l'utilisateur de repÃ©rer rapidement ses personnalisations.

---

## 3. Catalogue complet des paramÃ¨tres CHUNKING

### 3.1 ParamÃ¨tres de stratÃ©gie

| ParamÃ¨tre | ClÃ© config | Type | Options | DÃ©faut | Description |
|-----------|------------|------|---------|--------|-------------|
| StratÃ©gie de chunking | `chunking.strategy` | enum | `fixed_size` \| `sentence_based` \| `paragraph_based` \| `semantic` \| `recursive` \| `markdown_header` | Selon profil | MÃ©thode de dÃ©coupage des documents en chunks. **Impact critique** sur la qualitÃ© du RAG. |

### 3.2 ParamÃ¨tres de taille

| ParamÃ¨tre | ClÃ© config | Type | Min | Max | DÃ©faut | Description |
|-----------|------------|------|-----|-----|--------|-------------|
| Taille des chunks | `chunking.chunk_size` | int (tokens) | 64 | 4096 | Selon profil | Taille cible de chaque chunk. Trop petit = perte de contexte. Trop grand = mÃ©lange de sujets. |
| Chevauchement | `chunking.chunk_overlap` | int (tokens) | 0 | `chunk_size / 2` | Selon profil | Nombre de tokens partagÃ©s entre chunks consÃ©cutifs. 10-20% de `chunk_size` est recommandÃ©. |
| Taille minimale | `chunking.min_chunk_size` | int (tokens) | 10 | `chunk_size` | Selon profil | Les chunks infÃ©rieurs Ã  cette taille sont fusionnÃ©s avec le prÃ©cÃ©dent ou supprimÃ©s. Ã‰vite les micro-chunks. |
| Taille maximale | `chunking.max_chunk_size` | int (tokens) | `chunk_size` | 8192 | Selon profil | Taille absolue au-delÃ  de laquelle un chunk est forcÃ©ment re-dÃ©coupÃ©. Garde-fou contre les chunks gÃ©ants. |

**Validation croisÃ©e des tailles** :
- `chunk_overlap` < `chunk_size` (erreur sinon)
- `min_chunk_size` â‰¤ `chunk_size` (erreur sinon)
- `max_chunk_size` â‰¥ `chunk_size` (erreur sinon)
- `chunk_overlap` â‰¤ `chunk_size / 2` (avertissement sinon : "Un chevauchement supÃ©rieur Ã  50% de la taille des chunks est inhabituel.")

L'interface affiche les erreurs de validation en rouge sous le champ concernÃ© et dÃ©sactive le bouton de prÃ©visualisation tant qu'il y a une erreur.

### 3.3 ParamÃ¨tres d'options avancÃ©es

| ParamÃ¨tre | ClÃ© config | Type | DÃ©faut | Description |
|-----------|------------|------|--------|-------------|
| PrÃ©server les phrases | `chunking.preserve_sentences` | bool | `true` | Ne jamais couper un chunk au milieu d'une phrase. Le chunk peut lÃ©gÃ¨rement dÃ©passer `chunk_size` pour finir la phrase. |
| Propagation mÃ©tadonnÃ©es | `chunking.metadata_propagation` | bool | `true` | Chaque chunk hÃ©rite des mÃ©tadonnÃ©es de son document parent (titre, auteur, langue, source, etc.). |
| Index du chunk | `chunking.add_chunk_index` | bool | Selon profil | Ajoute l'index positionnel du chunk dans le document (0, 1, 2â€¦). Permet de reconstruire l'ordre original. |
| Titre du document | `chunking.add_document_title` | bool | `true` | Ajoute le titre du document parent dans les mÃ©tadonnÃ©es de chaque chunk. AmÃ©liore la recherche contextuelle. |
| Conserver sÃ©parateurs | `chunking.keep_separator` | bool | Selon profil | Conserve les sÃ©parateurs dans le texte du chunk (au lieu de les supprimer). Pertinent pour les documents juridiques. |

### 3.4 ParamÃ¨tres spÃ©cifiques aux stratÃ©gies

| ParamÃ¨tre | ClÃ© config | Type | DÃ©faut | Applicable Ã  | Description |
|-----------|------------|------|--------|-------------|-------------|
| SÃ©parateurs | `chunking.separators` | string[] | Selon profil | `recursive` | Liste ordonnÃ©e de sÃ©parateurs. Le chunker essaie le premier, puis passe au suivant si les chunks sont trop grands. |
| Seuil similaritÃ© | `chunking.similarity_threshold` | float (0-1) | Selon profil | `semantic` | Seuil en dessous duquel deux phrases adjacentes sont considÃ©rÃ©es comme traitant de sujets diffÃ©rents â†’ frontiÃ¨re de chunk. |
| Niveaux de titres | `chunking.header_levels` | int[] | Selon profil | `markdown_header` | Niveaux de titres Markdown qui dÃ©clenchent un nouveau chunk (ex: `[1, 2, 3]` = h1, h2, h3). |

### 3.5 RÃ©sumÃ© des impacts

| ParamÃ¨tre | Impact principal | Impact secondaire |
|-----------|-----------------|-------------------|
| `strategy` | **CRITIQUE** â€” CohÃ©rence contextuelle de chaque chunk | Temps de traitement (semantic est le plus lent) |
| `chunk_size` | Balance entre contexte et prÃ©cision | Affecte le nombre de chunks (et donc la taille de la BDD vectorielle) |
| `chunk_overlap` | ContinuitÃ© d'information aux frontiÃ¨res | Augmente le nombre de chunks (~10-20% supplÃ©mentaires) |
| `min_chunk_size` | Ã‰limine les chunks non informatifs | Peut perdre de l'info si trop haut |
| `max_chunk_size` | Garde-fou pour les modÃ¨les d'embedding | Rarement atteint en pratique |
| `preserve_sentences` | Chunks plus lisibles et cohÃ©rents | Taille des chunks lÃ©gÃ¨rement variable |
| `metadata_propagation` | TraÃ§abilitÃ© et capacitÃ© de filtrage | LÃ©gÃ¨re augmentation de la taille stockÃ©e |
| `separators` | QualitÃ© du dÃ©coupage rÃ©cursif | L'ordre est crucial : du plus grossier au plus fin |
| `similarity_threshold` | GranularitÃ© du dÃ©coupage sÃ©mantique | Seuil bas = gros chunks, seuil haut = petits chunks |

---

## 4. Valeurs par dÃ©faut par profil

Les valeurs par dÃ©faut sont dÃ©jÃ  calculÃ©es et stockÃ©es dans `settings.json` par le wizard de l'Ã‰tape 1 (section `chunking`). Cette Ã©tape **active et utilise** ces valeurs.

### 4.1 Matrice profil â†’ paramÃ¨tres de chunking

| ParamÃ¨tre | `technical_documentation` | `faq_support` | `legal_compliance` | `reports_analysis` | `general` |
|-----------|:---:|:---:|:---:|:---:|:---:|
| `strategy` | `recursive` | `paragraph_based` | `recursive` | `paragraph_based` | `fixed_size` |
| `chunk_size` | 512 | 256 | 1024 | 768 | 512 |
| `chunk_overlap` | 100 | 50 | 200 | 100 | 50 |
| `min_chunk_size` | 50 | 30 | 100 | 50 | 30 |
| `max_chunk_size` | 2000 | 1000 | 4000 | 3000 | 2000 |
| `preserve_sentences` | `true` | `true` | `true` | `true` | `true` |
| `metadata_propagation` | `true` | `true` | `true` | `true` | `true` |
| `add_chunk_index` | `true` | `false` | `true` | `true` | `true` |
| `add_document_title` | `true` | `true` | `true` | `true` | `true` |
| `keep_separator` | `false` | `false` | `true` | `false` | `false` |
| `separators` | `["\n\n", "\n", ". ", " "]` | `["\n\n", "\n"]` | `["\n\n", "\n", ". "]` | `["\n\n", "\n", ". ", " "]` | `["\n\n", "\n", ". ", " "]` |
| `similarity_threshold` | 0.75 | 0.80 | 0.70 | 0.75 | 0.75 |
| `header_levels` | `[1, 2, 3]` | `[1, 2]` | `[1, 2, 3, 4]` | `[1, 2, 3]` | `[1, 2, 3]` |

### 4.2 Justification des choix par profil

#### ğŸ“˜ `technical_documentation`

La documentation technique est bien structurÃ©e avec des titres, sous-titres, blocs de code et paragraphes distincts. La stratÃ©gie `recursive` avec les sÃ©parateurs `["\n\n", "\n", ". ", " "]` exploite cette structure en essayant d'abord de couper aux paragraphes, puis aux lignes, puis aux phrases. La taille de 512 tokens est un bon compromis entre contexte suffisant et prÃ©cision. L'index du chunk est activÃ© pour pouvoir reconstruire l'ordre des sections.

#### â“ `faq_support`

Les FAQ sont naturellement organisÃ©es en paires question/rÃ©ponse courtes. La stratÃ©gie `paragraph_based` isole chaque Q/R dans son propre chunk. La taille de 256 tokens est adaptÃ©e Ã  ces contenus courts. L'index du chunk est dÃ©sactivÃ© car l'ordre importe peu dans une FAQ.

#### ğŸ“œ `legal_compliance`

Les documents juridiques nÃ©cessitent un contexte large â€” un article de loi perd son sens s'il est coupÃ©. La taille de 1024 tokens et le `max_chunk_size` de 4000 garantissent des chunks substantiels. Le chevauchement de 200 tokens est Ã©levÃ© pour ne perdre aucune continuitÃ©. `keep_separator: true` prÃ©serve la numÃ©rotation des articles. Les niveaux de titres incluent h4 pour capturer les sous-articles.

#### ğŸ“Š `reports_analysis`

Les rapports sont narratifs avec des sections d'analyse longues. La stratÃ©gie `paragraph_based` Ã  768 tokens capture des passages complets. Les tableaux de donnÃ©es (extraits en Markdown Ã  l'Ã‰tape 1) sont conservÃ©s dans leurs chunks.

#### ğŸ“š `general`

Le profil universel utilise `fixed_size` Ã  512 tokens â€” le choix le plus robuste quand la structure du contenu est inconnue ou variÃ©e. Les paramÃ¨tres sont Ã©quilibrÃ©s et constituent un bon point de dÃ©part pour tout type de contenu.

### 4.3 Impact des modificateurs de calibrage sur le chunking

Rappel : les questions de calibrage de l'Ã‰tape 1 modifient les valeurs de base. Voici les modificateurs qui impactent le chunking :

| Question | Si OUI â†’ Modifications sur le chunking |
|----------|----------------------------------------|
| **Q3** : Documents > 50 pages ? | `chunk_size` Ã—= 1.5, `chunk_overlap` Ã—= 1.5, `max_chunk_size` Ã—= 1.5, `min_chunk_size` Ã—= 2 |
| **Q6** : Citations avec sources ? | `add_chunk_index` â†’ `true`, `metadata_propagation` â†’ `true`, `add_document_title` â†’ `true` |

Les autres questions (Q1, Q2, Q4, Q5) n'impactent pas directement les paramÃ¨tres de chunking.

---

## 5. SpÃ©cifications techniques

### 5.1 SchÃ©ma Pydantic (backend)

```python
# ragkit/config/chunking_schema.py
"""Pydantic schemas for chunking configuration."""

from __future__ import annotations

from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field, field_validator, model_validator


class ChunkingStrategy(str, Enum):
    FIXED_SIZE = "fixed_size"
    SENTENCE_BASED = "sentence_based"
    PARAGRAPH_BASED = "paragraph_based"
    SEMANTIC = "semantic"
    RECURSIVE = "recursive"
    MARKDOWN_HEADER = "markdown_header"


class ChunkingConfig(BaseModel):
    """Complete chunking configuration."""

    strategy: ChunkingStrategy = ChunkingStrategy.RECURSIVE
    chunk_size: int = Field(default=512, ge=64, le=4096,
        description="Target chunk size in tokens")
    chunk_overlap: int = Field(default=100, ge=0,
        description="Overlap between consecutive chunks in tokens")
    min_chunk_size: int = Field(default=50, ge=10,
        description="Minimum chunk size; smaller chunks are merged or discarded")
    max_chunk_size: int = Field(default=2000, le=8192,
        description="Absolute maximum chunk size")
    preserve_sentences: bool = Field(default=True,
        description="Never split in the middle of a sentence")
    metadata_propagation: bool = Field(default=True,
        description="Propagate parent document metadata to chunks")
    add_chunk_index: bool = Field(default=True,
        description="Add positional index to each chunk")
    add_document_title: bool = Field(default=True,
        description="Add document title to chunk metadata")
    keep_separator: bool = Field(default=False,
        description="Keep separators in chunk text (recursive strategy)")

    # Strategy-specific parameters
    separators: list[str] = Field(
        default=["\n\n", "\n", ". ", " "],
        description="Ordered list of separators (recursive strategy)")
    similarity_threshold: float = Field(
        default=0.75, ge=0.0, le=1.0,
        description="Semantic similarity threshold for topic change detection")
    header_levels: list[int] = Field(
        default=[1, 2, 3],
        description="Markdown heading levels that trigger new chunks")

    @model_validator(mode="after")
    def validate_size_constraints(self) -> "ChunkingConfig":
        """Ensure size parameters are logically consistent."""
        if self.chunk_overlap >= self.chunk_size:
            raise ValueError(
                f"chunk_overlap ({self.chunk_overlap}) must be less than "
                f"chunk_size ({self.chunk_size})")
        if self.min_chunk_size > self.chunk_size:
            raise ValueError(
                f"min_chunk_size ({self.min_chunk_size}) must be â‰¤ "
                f"chunk_size ({self.chunk_size})")
        if self.max_chunk_size < self.chunk_size:
            raise ValueError(
                f"max_chunk_size ({self.max_chunk_size}) must be â‰¥ "
                f"chunk_size ({self.chunk_size})")
        return self

    @field_validator("header_levels")
    @classmethod
    def validate_header_levels(cls, v: list[int]) -> list[int]:
        for level in v:
            if level < 1 or level > 6:
                raise ValueError(
                    f"Header level {level} out of range (1-6)")
        return sorted(set(v))


class ChunkMetadata(BaseModel):
    """Metadata attached to each chunk."""
    chunk_id: str
    chunk_index: int
    document_id: str
    document_title: str | None = None
    source_file: str
    page_start: int | None = None
    page_end: int | None = None
    language: str | None = None
    chunk_size_tokens: int
    overlap_tokens_before: int = 0
    overlap_tokens_after: int = 0


class Chunk(BaseModel):
    """A single chunk produced by the chunking pipeline."""
    content: str
    metadata: ChunkMetadata
```

### 5.2 Moteur de chunking (backend)

```python
# ragkit/chunking/engine.py
"""Chunking engine â€” dispatches to strategy implementations."""

from __future__ import annotations

from abc import ABC, abstractmethod

from ragkit.config.chunking_schema import Chunk, ChunkingConfig, ChunkingStrategy


class BaseChunker(ABC):
    """Abstract base class for all chunking strategies."""

    def __init__(self, config: ChunkingConfig):
        self.config = config

    @abstractmethod
    def chunk(self, text: str, metadata: dict) -> list[Chunk]:
        """Split text into chunks with metadata."""
        ...


class FixedSizeChunker(BaseChunker):
    """Splits text into fixed-size token windows."""
    ...


class SentenceBasedChunker(BaseChunker):
    """Groups complete sentences up to chunk_size."""
    ...


class ParagraphBasedChunker(BaseChunker):
    """Splits at paragraph boundaries."""
    ...


class SemanticChunker(BaseChunker):
    """Splits based on semantic similarity between adjacent sentences."""
    ...


class RecursiveChunker(BaseChunker):
    """Recursively splits using an ordered list of separators."""
    ...


class MarkdownHeaderChunker(BaseChunker):
    """Splits according to Markdown heading hierarchy."""
    ...


# Strategy registry
CHUNKER_REGISTRY: dict[ChunkingStrategy, type[BaseChunker]] = {
    ChunkingStrategy.FIXED_SIZE: FixedSizeChunker,
    ChunkingStrategy.SENTENCE_BASED: SentenceBasedChunker,
    ChunkingStrategy.PARAGRAPH_BASED: ParagraphBasedChunker,
    ChunkingStrategy.SEMANTIC: SemanticChunker,
    ChunkingStrategy.RECURSIVE: RecursiveChunker,
    ChunkingStrategy.MARKDOWN_HEADER: MarkdownHeaderChunker,
}


def create_chunker(config: ChunkingConfig) -> BaseChunker:
    """Factory function to create the appropriate chunker."""
    chunker_cls = CHUNKER_REGISTRY[config.strategy]
    return chunker_cls(config)
```

### 5.3 Tokenizer

Le comptage de tokens est central dans le chunking. Le backend utilise `tiktoken` (tokenizer d'OpenAI, modÃ¨le `cl100k_base`) comme rÃ©fÃ©rence pour le comptage.

```python
# ragkit/chunking/tokenizer.py
"""Token counting utility for chunking."""

import tiktoken


class TokenCounter:
    """Counts tokens using tiktoken (cl100k_base encoding)."""

    def __init__(self, encoding_name: str = "cl100k_base"):
        self.encoder = tiktoken.get_encoding(encoding_name)

    def count(self, text: str) -> int:
        """Count the number of tokens in a text."""
        return len(self.encoder.encode(text))

    def truncate(self, text: str, max_tokens: int) -> str:
        """Truncate text to a maximum number of tokens."""
        tokens = self.encoder.encode(text)
        if len(tokens) <= max_tokens:
            return text
        return self.encoder.decode(tokens[:max_tokens])
```

> **Note** : le choix de `tiktoken` est provisoire. Ã€ l'Ã‰tape 3 (Embedding), si le modÃ¨le d'embedding utilise un tokenizer diffÃ©rent, le tokenizer de chunking pourra Ãªtre alignÃ©. Pour l'instant, `cl100k_base` est un standard raisonnable.

### 5.4 API REST (routes backend)

#### 5.4.1 Routes Chunking Config

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/chunking/config` | GET | Config chunking courante | â€” | `ChunkingConfig` |
| `/api/chunking/config` | PUT | Met Ã  jour la config | `ChunkingConfig` (partiel) | `ChunkingConfig` |
| `/api/chunking/config/reset` | POST | RÃ©initialise au profil actif | â€” | `ChunkingConfig` |
| `/api/chunking/config/validate` | POST | Valide une config sans la sauver | `ChunkingConfig` | `{ valid: bool, errors: string[] }` |

#### 5.4.2 Routes PrÃ©visualisation

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/chunking/preview` | POST | Chunke un document avec la config courante | `{ document_id: string }` | `ChunkingPreviewResult` |
| `/api/chunking/preview/custom` | POST | Chunke avec une config personnalisÃ©e (non sauvÃ©e) | `{ document_id: string, config: ChunkingConfig }` | `ChunkingPreviewResult` |

#### 5.4.3 ModÃ¨les de rÃ©ponse

```python
class ChunkPreview(BaseModel):
    """A chunk in the preview result."""
    index: int
    content: str                    # Contenu textuel du chunk
    content_truncated: str          # TronquÃ© Ã  500 caractÃ¨res pour l'affichage
    size_tokens: int
    page_start: int | None
    page_end: int | None
    overlap_before: str | None      # Texte de chevauchement avec le chunk prÃ©cÃ©dent
    overlap_before_tokens: int
    overlap_after: str | None       # Texte de chevauchement avec le chunk suivant
    overlap_after_tokens: int
    metadata: dict                  # MÃ©tadonnÃ©es propagÃ©es


class ChunkingStats(BaseModel):
    """Statistics about the chunking result."""
    total_chunks: int
    avg_size_tokens: float
    min_size_tokens: int
    max_size_tokens: int
    median_size_tokens: float
    total_overlap_tokens: int       # Total de tokens dans les zones de chevauchement
    size_distribution: list[SizeBucket]


class SizeBucket(BaseModel):
    """A bucket in the size distribution histogram."""
    range_start: int                # Ex: 0
    range_end: int                  # Ex: 50
    count: int                      # Nombre de chunks dans cette tranche


class ChunkingPreviewResult(BaseModel):
    """Complete result of a chunking preview."""
    document_id: str
    document_title: str | None
    config_used: ChunkingConfig
    stats: ChunkingStats
    chunks: list[ChunkPreview]
    processing_time_ms: int         # Temps d'exÃ©cution en millisecondes
    warnings: list[str]             # Avertissements Ã©ventuels
```

### 5.5 Commandes Tauri (Rust) â€” ajouts

```rust
// desktop/src-tauri/src/commands.rs (ajouts Ã‰tape 2)

// Chunking config
#[tauri::command]
pub async fn get_chunking_config() -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn update_chunking_config(config: serde_json::Value) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn reset_chunking_config() -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn validate_chunking_config(config: serde_json::Value) -> Result<serde_json::Value, String> { ... }

// Chunking preview
#[tauri::command]
pub async fn preview_chunking(document_id: String) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn preview_chunking_custom(
    document_id: String,
    config: serde_json::Value
) -> Result<serde_json::Value, String> { ... }
```

### 5.6 Composants React â€” arborescence

```
desktop/src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â”œâ”€â”€ IngestionSettings.tsx          â† existant (Ã‰tape 1)
â”‚   â”‚   â”œâ”€â”€ SourceSettings.tsx             â† existant (Ã‰tape 1)
â”‚   â”‚   â”œâ”€â”€ ParsingSettings.tsx            â† existant (Ã‰tape 1)
â”‚   â”‚   â”œâ”€â”€ PreprocessingSettings.tsx      â† existant (Ã‰tape 1)
â”‚   â”‚   â”œâ”€â”€ MetadataTable.tsx              â† existant (Ã‰tape 1)
â”‚   â”‚   â”œâ”€â”€ ChunkingSettings.tsx           â† NOUVEAU : section complÃ¨te
â”‚   â”‚   â”œâ”€â”€ StrategySelector.tsx           â† NOUVEAU : sÃ©lecteur + description
â”‚   â”‚   â”œâ”€â”€ SizeParametersPanel.tsx        â† NOUVEAU : sliders taille/overlap/min/max
â”‚   â”‚   â”œâ”€â”€ AdvancedOptionsPanel.tsx       â† NOUVEAU : toggles options avancÃ©es
â”‚   â”‚   â”œâ”€â”€ SeparatorsEditor.tsx           â† NOUVEAU : Ã©diteur de liste de sÃ©parateurs
â”‚   â”‚   â””â”€â”€ ChunkingPreview.tsx            â† NOUVEAU : panneau de prÃ©visualisation
â”‚   â”œâ”€â”€ charts/
â”‚   â”‚   â””â”€â”€ SizeDistributionChart.tsx      â† NOUVEAU : histogramme distribution
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ ... (existants Ã‰tape 1)
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useWizard.ts                       â† existant (Ã‰tape 1)
â”‚   â”œâ”€â”€ useIngestionConfig.ts              â† existant (Ã‰tape 1)
â”‚   â”œâ”€â”€ useDocuments.ts                    â† existant (Ã‰tape 1)
â”‚   â”œâ”€â”€ useChunkingConfig.ts               â† NOUVEAU : hook config chunking
â”‚   â””â”€â”€ useChunkingPreview.ts              â† NOUVEAU : hook prÃ©visualisation
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ipc.ts                             â† MODIFIER : ajouter routes chunking
â””â”€â”€ locales/
    â”œâ”€â”€ fr.json                            â† MODIFIER : ajouter clÃ©s chunking
    â””â”€â”€ en.json                            â† MODIFIER : ajouter clÃ©s chunking
```

### 5.7 DÃ©tail des composants clÃ©s

#### `ChunkingSettings.tsx`

Composant principal de la section. Orchestre l'affichage conditionnel des sous-composants selon la stratÃ©gie sÃ©lectionnÃ©e.

```tsx
// Structure simplifiÃ©e
export function ChunkingSettings() {
  const { config, updateConfig, resetConfig, isDirty } = useChunkingConfig();
  const strategy = config.strategy;

  return (
    <SettingsSection title="CHUNKING">
      <StrategySelector
        value={strategy}
        onChange={(s) => updateConfig({ strategy: s })}
      />

      {strategy !== "markdown_header" && (
        <SizeParametersPanel config={config} onChange={updateConfig} />
      )}

      <AdvancedOptionsPanel
        config={config}
        strategy={strategy}
        onChange={updateConfig}
      />

      {strategy === "recursive" && (
        <SeparatorsEditor
          separators={config.separators}
          keepSeparator={config.keep_separator}
          onChange={updateConfig}
        />
      )}

      {strategy === "semantic" && (
        <SemanticParametersPanel config={config} onChange={updateConfig} />
      )}

      {strategy === "markdown_header" && (
        <HeaderLevelsSelector
          levels={config.header_levels}
          onChange={(levels) => updateConfig({ header_levels: levels })}
        />
      )}

      <ChunkingPreview config={config} />

      <ResetButton onClick={resetConfig} disabled={!isDirty} />
    </SettingsSection>
  );
}
```

#### `SeparatorsEditor.tsx`

Ã‰diteur interactif pour la liste de sÃ©parateurs :

```
â”Œâ”€â”€ SÃ©parateurs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                            â”‚
â”‚  1. ["\n\n"]  (double retour Ã  la ligne)         [âœ•]      â”‚
â”‚  2. ["\n"]    (retour Ã  la ligne)                [âœ•]      â”‚
â”‚  3. [". "]    (point + espace)                   [âœ•]      â”‚
â”‚  4. [" "]     (espace)                           [âœ•]      â”‚
â”‚                                                            â”‚
â”‚  [+ Ajouter un sÃ©parateur]                                 â”‚
â”‚                                                            â”‚
â”‚  â„¹ï¸ L'ordre est important : le chunker essaie le premier   â”‚
â”‚  sÃ©parateur, puis passe au suivant si les chunks sont      â”‚
â”‚  encore trop grands.                                       â”‚
â”‚                                                            â”‚
â”‚  [â†» RÃ©initialiser]                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Comportements** :
- Les sÃ©parateurs sont affichÃ©s en version lisible entre crochets, avec une description en gris.
- Drag-and-drop pour rÃ©ordonner.
- Bouton âœ• pour supprimer (min 1 sÃ©parateur obligatoire).
- Bouton "+ Ajouter" ouvre un champ texte pour saisir un nouveau sÃ©parateur (avec Ã©chappement automatique des caractÃ¨res spÃ©ciaux).
- CaractÃ¨res spÃ©ciaux courants proposÃ©s via des boutons rapides : `\n\n`, `\n`, `. `, ` `, `---`, `\t`.

### 5.8 Persistance

La config chunking est stockÃ©e dans la mÃªme structure `settings.json` existante :

```json
{
  "version": "1.0.0",
  "setup_completed": true,
  "profile": "legal_compliance",
  "calibration_answers": { "...": "..." },
  "ingestion": { "...": "..." },
  "chunking": {
    "strategy": "recursive",
    "chunk_size": 1536,
    "chunk_overlap": 300,
    "min_chunk_size": 200,
    "max_chunk_size": 6000,
    "preserve_sentences": true,
    "metadata_propagation": true,
    "add_chunk_index": true,
    "add_document_title": true,
    "keep_separator": true,
    "separators": ["\n\n", "\n", ". "],
    "similarity_threshold": 0.70,
    "header_levels": [1, 2, 3, 4]
  },
  "embedding": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 3" },
  "retrieval": { "...": "valeurs calculÃ©es, utilisÃ©es aux Ã‰tapes 5-7" },
  "rerank": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 8" },
  "llm": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 9" },
  "agents": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 10" }
}
```

> **Note** : l'exemple ci-dessus montre un profil `legal_compliance` avec Q3=OUI et Q6=OUI (valeurs modifiÃ©es par les modificateurs de calibrage).

### 5.9 DÃ©pendances Python ajoutÃ©es

```toml
# pyproject.toml â€” ajouts aux dependencies pour Ã‰tape 2
dependencies = [
    # ... (existants Ã‰tape 0 + Ã‰tape 1)
    "tiktoken>=0.5",               # Comptage de tokens (tokenizer OpenAI)
    "nltk>=3.8",                   # Sentence tokenization (PunktSentenceTokenizer)
    "sentence-transformers>=2.2",  # Embedding lÃ©ger pour chunking sÃ©mantique (preview only)
]
```

> **Note sur `sentence-transformers`** : cette dÃ©pendance est nÃ©cessaire uniquement pour la stratÃ©gie `semantic` en mode prÃ©visualisation. Le modÃ¨le lÃ©ger `all-MiniLM-L6-v2` (~80 Mo) est utilisÃ©. Il sera optionnellement remplacÃ© Ã  l'Ã‰tape 3 par le modÃ¨le d'embedding configurÃ© par l'utilisateur. Si l'utilisateur n'utilise pas la stratÃ©gie sÃ©mantique, le modÃ¨le n'est jamais tÃ©lÃ©chargÃ©/chargÃ©.

### 5.10 Algorithmes de chunking â€” comportements attendus

#### `fixed_size`

1. Compter les tokens du texte complet.
2. DÃ©couper en fenÃªtres de `chunk_size` tokens avec un dÃ©calage de `chunk_size - chunk_overlap`.
3. Si `preserve_sentences: true`, ajuster la fin du chunk pour ne pas couper une phrase (tolÃ©rance : +20% de `chunk_size`).
4. Supprimer les chunks < `min_chunk_size` (fusionner avec le prÃ©cÃ©dent si possible).

#### `sentence_based`

1. Segmenter le texte en phrases via `nltk.sent_tokenize()`.
2. Accumuler des phrases jusqu'Ã  atteindre `chunk_size` tokens.
3. CrÃ©er le chunk avec les phrases accumulÃ©es.
4. Le chevauchement reprend les N derniÃ¨res phrases du chunk prÃ©cÃ©dent pour atteindre `chunk_overlap` tokens.

#### `paragraph_based`

1. SÃ©parer le texte par `\n\n` (double retour Ã  la ligne).
2. Accumuler des paragraphes jusqu'Ã  atteindre `chunk_size`.
3. Si un seul paragraphe dÃ©passe `max_chunk_size`, le re-dÃ©couper en mode `sentence_based`.
4. Chevauchement : reprendre le dernier paragraphe du chunk prÃ©cÃ©dent.

#### `semantic`

1. Segmenter le texte en phrases.
2. Calculer l'embedding de chaque phrase via le modÃ¨le lÃ©ger embarquÃ©.
3. Calculer la similaritÃ© cosinus entre chaque paire de phrases consÃ©cutives.
4. Placer une frontiÃ¨re de chunk quand la similaritÃ© tombe sous `similarity_threshold`.
5. Si un chunk rÃ©sultant dÃ©passe `max_chunk_size`, le re-dÃ©couper en mode `sentence_based`.
6. Si un chunk est infÃ©rieur Ã  `min_chunk_size`, le fusionner avec le voisin le plus similaire.

#### `recursive`

1. Tenter de dÃ©couper avec le premier sÃ©parateur de la liste.
2. Pour chaque segment : si â‰¤ `chunk_size`, accepter comme chunk.
3. Si > `chunk_size`, re-dÃ©couper avec le sÃ©parateur suivant.
4. Si plus aucun sÃ©parateur, dÃ©couper en `fixed_size`.
5. Appliquer le chevauchement entre chunks.
6. Si `keep_separator: true`, conserver le sÃ©parateur au dÃ©but du chunk suivant.

#### `markdown_header`

1. DÃ©tecter les lignes commenÃ§ant par `#`, `##`, `###`, etc. (selon `header_levels`).
2. Chaque titre dans `header_levels` dÃ©clenche un nouveau chunk.
3. Le titre est inclus en en-tÃªte du chunk.
4. La hiÃ©rarchie est prÃ©servÃ©e dans les mÃ©tadonnÃ©es (ex : `section: "2.3.1 â€” Obligations du prestataire"`).
5. Si un chunk dÃ©passe `max_chunk_size`, le re-dÃ©couper en mode `paragraph_based`.
6. Si un chunk est infÃ©rieur Ã  `min_chunk_size`, le fusionner avec le suivant de mÃªme niveau.

---

## 6. CritÃ¨res d'acceptation

### 6.1 Fonctionnels

| # | CritÃ¨re |
|---|---------|
| F1 | La section `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > CHUNKING` est accessible et affiche tous les paramÃ¨tres |
| F2 | Le sÃ©lecteur de stratÃ©gie propose les 6 stratÃ©gies avec une description informative |
| F3 | Les paramÃ¨tres non pertinents pour la stratÃ©gie sÃ©lectionnÃ©e sont masquÃ©s dynamiquement |
| F4 | Les sliders de taille (chunk_size, overlap, min, max) sont fonctionnels avec validation croisÃ©e |
| F5 | Les erreurs de validation (overlap â‰¥ chunk_size, etc.) s'affichent en rouge sous le champ |
| F6 | Le badge "ModifiÃ©" apparaÃ®t Ã  cÃ´tÃ© de chaque paramÃ¨tre dont la valeur diffÃ¨re du profil |
| F7 | L'Ã©diteur de sÃ©parateurs permet d'ajouter, supprimer et rÃ©ordonner (drag-and-drop) |
| F8 | Le bouton "PrÃ©visualiser le chunking" chunke le document sÃ©lectionnÃ© et affiche les rÃ©sultats |
| F9 | La prÃ©visualisation affiche les statistiques (total, moyenne, min, max) |
| F10 | Les chunks sont affichÃ©s avec pagination (2 par page), index, taille et mÃ©tadonnÃ©es |
| F11 | La zone de chevauchement est surlignÃ©e en jaune pÃ¢le dans la prÃ©visualisation |
| F12 | L'histogramme de distribution des tailles est affichÃ© |
| F13 | Un avertissement s'affiche si > 200 chunks sont produits |
| F14 | Un avertissement s'affiche pour la stratÃ©gie `semantic` sans modÃ¨le d'embedding configurÃ© |
| F15 | Le bouton "RÃ©initialiser au profil" restaure les valeurs par dÃ©faut avec confirmation |
| F16 | Tous les textes sont traduits FR/EN via i18n |

### 6.2 Techniques

| # | CritÃ¨re |
|---|---------|
| T1 | `GET /api/chunking/config` retourne la config chunking courante |
| T2 | `PUT /api/chunking/config` valide et persiste les modifications |
| T3 | `POST /api/chunking/config/validate` dÃ©tecte les erreurs (overlap â‰¥ size, etc.) |
| T4 | `POST /api/chunking/config/reset` restaure les valeurs du profil actif |
| T5 | `POST /api/chunking/preview` retourne les chunks avec stats pour un document donnÃ© |
| T6 | Les 6 stratÃ©gies produisent des chunks valides sur des documents PDF, DOCX, MD et TXT |
| T7 | Le comptage de tokens est cohÃ©rent (tiktoken `cl100k_base`) |
| T8 | `preserve_sentences: true` ne produit jamais un chunk coupant une phrase en deux |
| T9 | `chunk_overlap` produit le bon texte commun entre chunks consÃ©cutifs (vÃ©rifiable en preview) |
| T10 | Les mÃ©tadonnÃ©es sont correctement propagÃ©es quand `metadata_propagation: true` |
| T11 | La config chunking est persistÃ©e dans `settings.json` sous la clÃ© `chunking` |
| T12 | Le pipeline parsing â†’ chunking fonctionne de bout en bout (parsing Ã‰tape 1 â†’ chunking Ã‰tape 2) |
| T13 | `tsc --noEmit` ne produit aucune erreur TypeScript |
| T14 | Le CI passe sur les 4 targets (lint + build) |

---

## 7. PÃ©rimÃ¨tre exclus (Ã‰tape 2)

- **Embedding** : sera ajoutÃ© Ã  l'Ã‰tape 3.
- **Stockage vectoriel** : sera ajoutÃ© Ã  l'Ã‰tape 4.
- **Ingestion persistante** : le chunking s'exÃ©cute pour la prÃ©visualisation mais les chunks ne sont pas persistÃ©s (pas de BDD vectorielle).
- **ParamÃ¨tres gÃ©nÃ©raux** : restent vides Ã  cette Ã©tape.
- **Chat fonctionnel** : reste un placeholder.
- **Tableau de bord fonctionnel** : reste un placeholder.
- **Chunking parent-child** : prÃ©vu en amÃ©lioration future (pas dans cette Ã©tape). Les paramÃ¨tres `parent_chunk_size`, `child_chunk_size` et `sentence_window_size` du guide exhaustif ne sont pas exposÃ©s.
- **Chunking sÃ©mantique avec le modÃ¨le d'embedding utilisateur** : Ã  l'Ã‰tape 2, seul un modÃ¨le lÃ©ger embarquÃ© est utilisÃ© pour le sÃ©mantique. L'intÃ©gration avec le modÃ¨le d'embedding configurÃ© sera faite Ã  l'Ã‰tape 3.

---

## 8. Estimation

| TÃ¢che | Effort estimÃ© |
|-------|---------------|
| SchÃ©ma Pydantic chunking + validation croisÃ©e | 0.5 jour |
| ImplÃ©mentation `FixedSizeChunker` | 0.5 jour |
| ImplÃ©mentation `SentenceBasedChunker` (+ intÃ©gration nltk) | 1 jour |
| ImplÃ©mentation `ParagraphBasedChunker` | 0.5 jour |
| ImplÃ©mentation `SemanticChunker` (+ modÃ¨le lÃ©ger embarquÃ©) | 1.5 jours |
| ImplÃ©mentation `RecursiveChunker` | 1 jour |
| ImplÃ©mentation `MarkdownHeaderChunker` | 1 jour |
| Tokenizer (`tiktoken`) + utilitaires de comptage | 0.5 jour |
| Routes API chunking (config CRUD + validation + preview) | 1 jour |
| Commandes Tauri (Rust) | 0.5 jour |
| Composant `ChunkingSettings.tsx` (orchestrateur + affichage conditionnel) | 1 jour |
| Composant `StrategySelector.tsx` + descriptions | 0.5 jour |
| Composant `SizeParametersPanel.tsx` (sliders + validation) | 0.5 jour |
| Composant `SeparatorsEditor.tsx` (drag-and-drop + Ã©dition) | 1 jour |
| Composant `ChunkingPreview.tsx` (prÃ©visualisation paginÃ©e + overlap surlignÃ©) | 1.5 jours |
| Composant `SizeDistributionChart.tsx` (histogramme) | 0.5 jour |
| Hook `useChunkingConfig.ts` + `useChunkingPreview.ts` | 0.5 jour |
| Traductions i18n (FR + EN) â€” chunking + stratÃ©gies | 0.5 jour |
| Tests unitaires chunkers (6 stratÃ©gies Ã— documents variÃ©s) | 2 jours |
| Tests d'intÃ©gration (pipeline parsing â†’ chunking) | 1 jour |
| Tests manuels + corrections | 1 jour |
| **Total** | **~17 jours** |
