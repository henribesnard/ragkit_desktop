# ğŸ§° RAGKIT Desktop â€” SpÃ©cifications Ã‰tape 5 : Recherche sÃ©mantique

> **Ã‰tape** : 5 â€” Recherche sÃ©mantique  
> **Tag cible** : `v0.6.0`  
> **Date** : 16 fÃ©vrier 2026  
> **DÃ©pÃ´t** : https://github.com/henribesnard/ragkit_desktop.git  
> **PrÃ©requis** : Ã‰tape 4 (Base de donnÃ©es vectorielle) implÃ©mentÃ©e et validÃ©e

---

## 1. Objectif

Ajouter le **premier mode de recherche fonctionnel** : la recherche sÃ©mantique par similaritÃ© vectorielle. L'utilisateur peut soumettre une requÃªte en langage naturel dans le CHAT et voir les chunks les plus pertinents extraits de sa base de connaissances.

Cette Ã©tape livre :
- Une section `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > RECHERCHE SÃ‰MANTIQUE` complÃ¨te et fonctionnelle.
- L'**activation de l'onglet CHAT** avec un champ de requÃªte et un affichage structurÃ© des rÃ©sultats.
- Un **moteur de recherche sÃ©mantique** qui embed la requÃªte utilisateur, interroge la BDD vectorielle, filtre et renvoie les chunks pertinents.
- Le support du **filtrage par mÃ©tadonnÃ©es** (source, type de document, langue, date, catÃ©gorie).
- La **diversification des rÃ©sultats** via MMR (Maximal Marginal Relevance) pour Ã©viter la redondance.
- Un **mode debug** optionnel affichant les scores, latences et dÃ©tails techniques de chaque rÃ©sultat.

**Pas de gÃ©nÃ©ration LLM** Ã  cette Ã©tape. Le chat affiche uniquement les rÃ©sultats bruts de la recherche (chunks avec scores et sources). C'est un outil de validation de la qualitÃ© de l'ingestion avant l'ajout du LLM (Ã‰tape 9).

---

## 2. SpÃ©cifications fonctionnelles

### 2.1 Section PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > RECHERCHE SÃ‰MANTIQUE

#### Structure de l'onglet PARAMÃˆTRES Ã  cette Ã©tape

```
PARAMÃˆTRES
â”œâ”€â”€ ParamÃ¨tres gÃ©nÃ©raux
â”‚   â””â”€â”€ Mode d'ingestion (Manuel / Automatique)     â† Ã‰tape 4
â””â”€â”€ ParamÃ¨tres avancÃ©s
    â”œâ”€â”€ INGESTION & PRÃ‰PROCESSING                    â† Ã‰tape 1
    â”œâ”€â”€ CHUNKING                                     â† Ã‰tape 2
    â”œâ”€â”€ EMBEDDING                                    â† Ã‰tape 3
    â”œâ”€â”€ BASE DE DONNÃ‰ES VECTORIELLE                  â† Ã‰tape 4
    â””â”€â”€ RECHERCHE SÃ‰MANTIQUE                         â† NOUVEAU
```

#### Layout de la section RECHERCHE SÃ‰MANTIQUE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RECHERCHE SÃ‰MANTIQUE                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ ParamÃ¨tres principaux â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â˜‘ Recherche sÃ©mantique activÃ©e                           â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  Nombre de rÃ©sultats (top_k) :  [===â—†======] 15           â”‚ â”‚
â”‚  â”‚  Seuil de similaritÃ© :          [â—†=========] 0.0          â”‚ â”‚
â”‚  â”‚  Poids (recherche hybride) :    [====â—†=====] 0.5          â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â„¹ï¸ top_k : nombre de chunks retournÃ©s par la recherche.   â”‚ â”‚
â”‚  â”‚  Un seuil de similaritÃ© > 0 filtre les rÃ©sultats peu      â”‚ â”‚
â”‚  â”‚  pertinents (0.0 = pas de filtre).                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Diversification (MMR) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â˜‘ Activer MMR (Maximal Marginal Relevance)               â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  Lambda (pertinence â†” diversitÃ©) : [=====â—†====] 0.5       â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â„¹ï¸ MMR rÃ©duit la redondance en diversifiant les rÃ©sultats.â”‚ â”‚
â”‚  â”‚  Lambda = 1.0 : max pertinence, Lambda = 0.0 : max        â”‚ â”‚
â”‚  â”‚  diversitÃ©. 0.5 est un bon compromis.                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Filtres par mÃ©tadonnÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â˜ Activer les filtres par dÃ©faut                         â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  (si activÃ© :)                                            â”‚ â”‚
â”‚  â”‚  Source(s) :      [â–¾ Tous les documents          ] â˜‘      â”‚ â”‚
â”‚  â”‚  Type(s) :        [â–¾ Tous les types              ] â˜‘      â”‚ â”‚
â”‚  â”‚  Langue(s) :      [â–¾ Toutes les langues          ] â˜‘      â”‚ â”‚
â”‚  â”‚  CatÃ©gorie(s) :   [â–¾ Toutes les catÃ©gories       ] â˜‘      â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â„¹ï¸ Les filtres par dÃ©faut s'appliquent Ã  toutes les       â”‚ â”‚
â”‚  â”‚  recherches. L'utilisateur peut aussi filtrer au cas       â”‚ â”‚
â”‚  â”‚  par cas dans le chat.                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â–¸ ParamÃ¨tres avancÃ©s                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ef_search (Qdrant) :    [=====â—†======] 128               â”‚ â”‚
â”‚  â”‚  Prefetch multiplier :   [==â—†=========] 3                 â”‚ â”‚
â”‚  â”‚  â˜ Mode debug activÃ© par dÃ©faut                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  [â†» RÃ©initialiser au profil]                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Activation de l'onglet CHAT

L'onglet CHAT Ã©tait un placeholder ("Le chat sera disponible aprÃ¨s configuration") depuis l'Ã‰tape 0. Ã€ l'Ã‰tape 5, il devient fonctionnel.

**PrÃ©requis pour activer le chat** : au moins une ingestion rÃ©ussie (index non vide). Si l'index est vide, un message s'affiche :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¬ CHAT                                                     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                                                    â”‚     â”‚
â”‚  â”‚    ğŸ“š Base de connaissances vide                    â”‚     â”‚
â”‚  â”‚                                                    â”‚     â”‚
â”‚  â”‚    Lancez une ingestion depuis le Tableau de bord   â”‚     â”‚
â”‚  â”‚    pour pouvoir interroger vos documents.           â”‚     â”‚
â”‚  â”‚                                                    â”‚     â”‚
â”‚  â”‚    [â†’ Aller au Tableau de bord]                     â”‚     â”‚
â”‚  â”‚                                                    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Layout du CHAT (avec rÃ©sultats)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¬ CHAT                                           [âš™ Options] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Barre de recherche â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ” [Posez votre question...                        ] [â†’]  â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  Filtres rapides :                                        â”‚ â”‚
â”‚  â”‚  [â–¾ Tous les documents] [â–¾ Toutes les langues]           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€ RÃ©sultats pour "conditions de rÃ©siliation du contrat" â”€â”€â”€â”€ â”‚
â”‚  â”€â”€ 15 chunks trouvÃ©s Â· 245 ms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ RÃ©sultat #1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Score : 0.892 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  ğŸ“„ contrat-service-2024.pdf Â· Page 8                     â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  "Les conditions de rÃ©siliation anticipÃ©e sont dÃ©finies    â”‚ â”‚
â”‚  â”‚  Ã  l'article 12 du prÃ©sent contrat. Le prestataire peut   â”‚ â”‚
â”‚  â”‚  rÃ©silier le contrat avec un prÃ©avis de 90 jours en cas   â”‚ â”‚
â”‚  â”‚  de manquement grave aux obligations..."                   â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  ğŸ“ Juridique Â· ğŸ· contrat, rÃ©siliation Â· ğŸŒ fr          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ RÃ©sultat #2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Score : 0.847 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  ğŸ“„ CGV-2024.pdf Â· Page 3                                 â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  "Article 7 â€” RÃ©siliation. Le client peut mettre fin      â”‚ â”‚
â”‚  â”‚  au contrat Ã  tout moment par lettre recommandÃ©e. Les     â”‚ â”‚
â”‚  â”‚  sommes versÃ©es ne sont remboursables que dans les         â”‚ â”‚
â”‚  â”‚  conditions prÃ©vues Ã  l'article 9..."                      â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  ğŸ“ Juridique Â· ğŸ· CGV, rÃ©siliation Â· ğŸŒ fr              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ RÃ©sultat #3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Score : 0.783 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ...                                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  [â–¼ Voir plus de rÃ©sultats] (affiche 5 par page)               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Mode debug (si activÃ©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  RequÃªte : "conditions de rÃ©siliation du contrat"         â”‚ â”‚
â”‚  â”‚  Tokens requÃªte : 7 Â· Embedding : 132 ms                 â”‚ â”‚
â”‚  â”‚  Recherche vectorielle : 113 ms Â· MMR : 8 ms             â”‚ â”‚
â”‚  â”‚  Total : 253 ms Â· RÃ©sultats avant filtre : 15            â”‚ â”‚
â”‚  â”‚  RÃ©sultats aprÃ¨s seuil : 15 (seuil = 0.0)               â”‚ â”‚
â”‚  â”‚  RÃ©sultats aprÃ¨s MMR : 15                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Flux de la recherche sÃ©mantique

```
1. L'utilisateur saisit une requÃªte dans la barre de recherche
2. La requÃªte est envoyÃ©e au backend
3. Le backend :
   a. Vectorise la requÃªte (embed_query via le modÃ¨le d'embedding configurÃ©)
   b. Interroge la BDD vectorielle (top_k Ã— prefetch_multiplier rÃ©sultats)
   c. Applique le seuil de similaritÃ© (filtre les scores < threshold)
   d. Applique les filtres par mÃ©tadonnÃ©es (si configurÃ©s)
   e. Applique MMR (si activÃ©) pour diversifier les rÃ©sultats
   f. Tronque Ã  top_k rÃ©sultats finaux
4. Les rÃ©sultats sont renvoyÃ©s au frontend
5. Le frontend affiche les rÃ©sultats avec mise en forme
```

### 2.4 Affichage d'un rÃ©sultat

Chaque rÃ©sultat (chunk) est affichÃ© dans une carte contenant :

| Ã‰lÃ©ment | Source | Affichage |
|---------|--------|-----------|
| **Score** | Score de similaritÃ© (0.0â€“1.0) | Badge en haut Ã  droite avec code couleur |
| **Source** | `payload.doc_title` ou `payload.doc_path` | ğŸ“„ Nom du document |
| **Page** | `payload.page_number` (si disponible) | "Â· Page N" |
| **Texte** | `payload.chunk_text` | Extrait du chunk (max 300 caractÃ¨res, avec "..." si tronquÃ©). La requÃªte est surlignÃ©e dans le texte. |
| **CatÃ©gorie** | `payload.category` | ğŸ“ Nom de catÃ©gorie |
| **Tags** | `payload.keywords` | ğŸ· Tags sÃ©parÃ©s par virgule |
| **Langue** | `payload.doc_language` | ğŸŒ Code langue |

**Code couleur du score** :

| Score | Couleur | Label |
|-------|---------|-------|
| 0.85 â€” 1.0 | Vert | TrÃ¨s pertinent |
| 0.70 â€” 0.85 | Vert clair | Pertinent |
| 0.50 â€” 0.70 | Orange | ModÃ©rÃ© |
| 0.0 â€” 0.50 | Rouge | Faible |

**Action sur clic** : cliquer sur la carte dÃ©ploie le texte complet du chunk et affiche toutes les mÃ©tadonnÃ©es dÃ©taillÃ©es (index du chunk, nombre de tokens, section source, hash du document, version d'ingestion).

### 2.5 Filtres rapides dans le chat

Sous la barre de recherche, des dropdowns permettent de filtrer les rÃ©sultats :

| Filtre | Valeurs | Source |
|--------|---------|--------|
| **Documents** | Liste de tous les documents indexÃ©s | `payload.doc_title` distinct |
| **Langues** | Liste des langues dÃ©tectÃ©es | `payload.doc_language` distinct |
| **Types** | PDF, DOCX, Markdown, TXT, HTML | `payload.doc_type` distinct |
| **CatÃ©gories** | Liste des catÃ©gories assignÃ©es | `payload.category` distinct |

**Comportements** :
- Les filtres sont des multi-sÃ©lections (on peut sÃ©lectionner plusieurs documents, plusieurs langues, etc.).
- "Tous" est la valeur par dÃ©faut (aucun filtre).
- Les filtres sont envoyÃ©s au backend comme conditions sur le `payload` de la recherche vectorielle.
- Les listes de valeurs disponibles sont chargÃ©es dynamiquement depuis l'index (requÃªte `distinct` sur les payloads).

### 2.6 Diversification MMR

Le **Maximal Marginal Relevance** (MMR) est un algorithme qui rÃ©-ordonne les rÃ©sultats pour rÃ©duire la redondance. Il balance entre la pertinence (similaritÃ© avec la requÃªte) et la diversitÃ© (dissimilaritÃ© entre les rÃ©sultats).

**Algorithme** :

```
MMR(Di) = Î» Ã— Sim(Di, Q) - (1 - Î») Ã— max(Sim(Di, Dj))
                                       j âˆˆ S

oÃ¹ :
  Di = candidat courant
  Q  = requÃªte
  S  = rÃ©sultats dÃ©jÃ  sÃ©lectionnÃ©s
  Î»  = paramÃ¨tre lambda (0.0 = max diversitÃ©, 1.0 = max pertinence)
```

**ImplÃ©mentation** :
1. RÃ©cupÃ©rer `top_k Ã— prefetch_multiplier` rÃ©sultats depuis la BDD vectorielle.
2. SÃ©lectionner itÃ©rativement les rÃ©sultats finaux en maximisant le score MMR.
3. Retourner `top_k` rÃ©sultats.

### 2.7 Mode debug

Le mode debug affiche un panneau en bas des rÃ©sultats avec les informations techniques de la recherche.

**Informations affichÃ©es** :

| MÃ©trique | Description |
|----------|-------------|
| RequÃªte | Texte de la requÃªte originale |
| Tokens requÃªte | Nombre de tokens de la requÃªte |
| Latence embedding | Temps de vectorisation de la requÃªte (ms) |
| Latence recherche | Temps de recherche dans la BDD vectorielle (ms) |
| Latence MMR | Temps de calcul MMR (ms) |
| Latence totale | Temps total bout-en-bout (ms) |
| RÃ©sultats bruts | Nombre de rÃ©sultats retournÃ©s par la BDD vectorielle |
| AprÃ¨s seuil | Nombre de rÃ©sultats aprÃ¨s filtrage par seuil |
| AprÃ¨s filtres | Nombre de rÃ©sultats aprÃ¨s filtrage par mÃ©tadonnÃ©es |
| AprÃ¨s MMR | Nombre de rÃ©sultats finaux aprÃ¨s MMR |

**Activation** :
- Toggle dans `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > RECHERCHE SÃ‰MANTIQUE > ParamÃ¨tres avancÃ©s > Mode debug activÃ© par dÃ©faut`.
- Toggle rapide dans le chat via le bouton "âš™ Options" en haut Ã  droite â†’ "Afficher le mode debug".

### 2.8 Bouton Options du CHAT

Le bouton "âš™ Options" en haut Ã  droite du CHAT ouvre un panneau latÃ©ral ou un dropdown avec :

| Option | Type | Description |
|--------|------|-------------|
| Mode debug | Toggle | Afficher/masquer le panneau debug |
| RÃ©sultats par page | Dropdown | 5, 10, 15, 20 (dÃ©faut : 5) |
| Afficher les scores | Toggle | Montrer/cacher les scores de similaritÃ© |
| Afficher les mÃ©tadonnÃ©es | Toggle | Montrer/cacher catÃ©gorie, tags, langue |

Ces options sont **locales au chat** (non persistÃ©es dans `settings.json`). Elles reviennent Ã  leurs valeurs par dÃ©faut Ã  chaque redÃ©marrage.

---

## 3. Catalogue complet des paramÃ¨tres RECHERCHE SÃ‰MANTIQUE

### 3.1 ParamÃ¨tres principaux

| ParamÃ¨tre | ClÃ© config | Type | Min | Max | DÃ©faut | Description |
|-----------|------------|------|-----|-----|--------|-------------|
| ActivÃ©e | `retrieval.semantic.enabled` | bool | â€” | â€” | `true` | Activer/dÃ©sactiver la recherche sÃ©mantique |
| Top K | `retrieval.semantic.top_k` | int | 1 | 100 | Selon profil | Nombre maximum de chunks retournÃ©s |
| Seuil de similaritÃ© | `retrieval.semantic.threshold` | float | 0.0 | 1.0 | Selon profil | Score minimum pour inclure un rÃ©sultat. 0.0 = pas de filtre. |
| Poids | `retrieval.semantic.weight` | float | 0.0 | 1.0 | Selon profil | Poids de la recherche sÃ©mantique dans le score hybride (utilisÃ© aux Ã‰tapes 7+). |

### 3.2 ParamÃ¨tres de diversification (MMR)

| ParamÃ¨tre | ClÃ© config | Type | Min | Max | DÃ©faut | Description |
|-----------|------------|------|-----|-----|--------|-------------|
| MMR activÃ© | `retrieval.semantic.mmr_enabled` | bool | â€” | â€” | `false` | Activer la diversification par MMR |
| Lambda | `retrieval.semantic.mmr_lambda` | float | 0.0 | 1.0 | 0.5 | Balance pertinence (1.0) â†” diversitÃ© (0.0) |

### 3.3 Filtres par mÃ©tadonnÃ©es (par dÃ©faut)

| ParamÃ¨tre | ClÃ© config | Type | DÃ©faut | Description |
|-----------|------------|------|--------|-------------|
| Filtres activÃ©s | `retrieval.semantic.default_filters_enabled` | bool | `false` | Appliquer des filtres par dÃ©faut Ã  toutes les recherches |
| Documents | `retrieval.semantic.default_filters.doc_ids` | list[str] | `[]` | Liste de `doc_id` Ã  inclure (vide = tous) |
| Types | `retrieval.semantic.default_filters.doc_types` | list[str] | `[]` | Types de documents (vide = tous) |
| Langues | `retrieval.semantic.default_filters.languages` | list[str] | `[]` | Langues (vide = toutes) |
| CatÃ©gories | `retrieval.semantic.default_filters.categories` | list[str] | `[]` | CatÃ©gories (vide = toutes) |

### 3.4 ParamÃ¨tres avancÃ©s

| ParamÃ¨tre | ClÃ© config | Type | Min | Max | DÃ©faut | Description |
|-----------|------------|------|-----|-----|--------|-------------|
| Prefetch multiplier | `retrieval.semantic.prefetch_multiplier` | int | 1 | 10 | 3 | Multiplier le `top_k` pour avoir plus de candidats avant MMR et filtrage. |
| Debug par dÃ©faut | `retrieval.semantic.debug_default` | bool | â€” | â€” | `false` | Activer le mode debug par dÃ©faut dans le chat |

### 3.5 RÃ©sumÃ© des impacts

| ParamÃ¨tre | Impact principal | Impact secondaire |
|-----------|-----------------|-------------------|
| `top_k` | **CRITIQUE** â€” Nombre de rÃ©sultats. Trop peu = rÃ©sultats manquants. Trop = bruit. | Latence de recherche (marginal pour <100) |
| `threshold` | Filtre les rÃ©sultats peu pertinents | Risque de "0 rÃ©sultat" si trop Ã©levÃ© |
| `weight` | Poids dans la recherche hybride (Ã‰tape 7) | Aucun impact Ã  cette Ã©tape (utilisÃ© seul) |
| `mmr_enabled` + `mmr_lambda` | DiversitÃ© des rÃ©sultats | LÃ©gÃ¨re augmentation de la latence |
| `prefetch_multiplier` | QualitÃ© du pool de candidats pour MMR | Latence de recherche vectorielle |

---

## 4. Valeurs par dÃ©faut par profil

### 4.1 Matrice profil â†’ paramÃ¨tres de recherche sÃ©mantique

| ParamÃ¨tre | `technical_documentation` | `faq_support` | `legal_compliance` | `reports_analysis` | `general` |
|-----------|:---:|:---:|:---:|:---:|:---:|
| `enabled` | `true` | `true` | `true` | `true` | `true` |
| `top_k` | 15 | 5 | 20 | 15 | 10 |
| `threshold` | 0.0 | 0.3 | 0.0 | 0.0 | 0.0 |
| `weight` | 0.5 | 1.0 | 0.5 | 0.6 | 0.5 |
| `mmr_enabled` | `false` | `false` | `false` | `false` | `false` |
| `mmr_lambda` | 0.5 | 0.5 | 0.5 | 0.5 | 0.5 |
| `prefetch_multiplier` | 3 | 2 | 3 | 3 | 3 |
| `debug_default` | `false` | `false` | `false` | `false` | `false` |

### 4.2 Justification des choix

- **`faq_support` â†’ `top_k=5`, `threshold=0.3`** : les bases FAQ ont des rÃ©ponses courtes et ciblÃ©es. Un `top_k` faible avec un seuil non nul Ã©vite de noyer l'utilisateur. Le `weight=1.0` signifie qu'Ã  terme (recherche hybride), le profil FAQ se base uniquement sur le sÃ©mantique.
- **`legal_compliance` â†’ `top_k=20`** : le contexte juridique nÃ©cessite de remonter un maximum de chunks pertinents pour ne rien manquer. Le seuil est Ã  0 car tout document potentiellement pertinent doit Ãªtre examinÃ©.
- **`technical_documentation` â†’ `top_k=15`** : bon compromis entre exhaustivitÃ© et pertinence pour de la doc technique. Le `weight=0.5` prÃ©pare la recherche hybride Ã  50/50 avec le lexical.
- **`reports_analysis` â†’ `weight=0.6`** : les rapports bÃ©nÃ©ficient d'un poids sÃ©mantique lÃ©gÃ¨rement supÃ©rieur car les requÃªtes sont souvent conceptuelles ("Ã©volution du CA").

---

## 5. SpÃ©cifications techniques

### 5.1 SchÃ©ma Pydantic (backend)

```python
# ragkit/config/retrieval_schema.py
"""Pydantic schemas for semantic search configuration."""

from __future__ import annotations

from pydantic import BaseModel, Field


class MetadataFilters(BaseModel):
    """Default metadata filters applied to all searches."""
    doc_ids: list[str] = Field(default_factory=list)
    doc_types: list[str] = Field(default_factory=list)
    languages: list[str] = Field(default_factory=list)
    categories: list[str] = Field(default_factory=list)


class SemanticSearchConfig(BaseModel):
    """Semantic search configuration."""

    enabled: bool = True
    top_k: int = Field(default=10, ge=1, le=100)
    threshold: float = Field(default=0.0, ge=0.0, le=1.0)
    weight: float = Field(default=0.5, ge=0.0, le=1.0,
        description="Weight in hybrid search (Ã‰tape 7)")

    # MMR
    mmr_enabled: bool = False
    mmr_lambda: float = Field(default=0.5, ge=0.0, le=1.0)

    # Default filters
    default_filters_enabled: bool = False
    default_filters: MetadataFilters = Field(
        default_factory=MetadataFilters)

    # Advanced
    prefetch_multiplier: int = Field(default=3, ge=1, le=10)
    debug_default: bool = False
```

### 5.2 Moteur de recherche sÃ©mantique (backend)

```python
# ragkit/retrieval/semantic_engine.py
"""Semantic search engine â€” vector similarity search with MMR."""

from __future__ import annotations

import time
from dataclasses import dataclass, field

import numpy as np

from ragkit.config.retrieval_schema import SemanticSearchConfig, MetadataFilters
from ragkit.embedding.engine import BaseEmbeddingProvider
from ragkit.storage.base import BaseVectorStore


@dataclass
class SearchResult:
    """A single search result (chunk with score and metadata)."""
    chunk_id: str
    score: float
    text: str
    metadata: dict
    # Populated from payload:
    doc_title: str | None = None
    doc_path: str | None = None
    doc_type: str | None = None
    page_number: int | None = None
    chunk_index: int | None = None
    chunk_total: int | None = None
    section_header: str | None = None
    doc_language: str | None = None
    category: str | None = None
    keywords: list[str] = field(default_factory=list)


@dataclass
class SearchDebugInfo:
    """Debug information for a search query."""
    query_text: str
    query_tokens: int
    embedding_latency_ms: int
    search_latency_ms: int
    mmr_latency_ms: int
    total_latency_ms: int
    results_from_db: int
    results_after_threshold: int
    results_after_filters: int
    results_after_mmr: int


@dataclass
class SemanticSearchResponse:
    """Complete response from a semantic search."""
    query: str
    results: list[SearchResult]
    total_results: int
    debug: SearchDebugInfo | None = None


class SemanticSearchEngine:
    """Performs semantic search with optional MMR diversification."""

    def __init__(
        self,
        config: SemanticSearchConfig,
        embedder: BaseEmbeddingProvider,
        store: BaseVectorStore,
    ):
        self.config = config
        self.embedder = embedder
        self.store = store

    async def search(
        self,
        query: str,
        top_k: int | None = None,
        threshold: float | None = None,
        filters: MetadataFilters | None = None,
        mmr_enabled: bool | None = None,
        mmr_lambda: float | None = None,
        include_debug: bool = False,
    ) -> SemanticSearchResponse:
        """Execute a semantic search query."""

        # Use provided params or fall back to config defaults
        _top_k = top_k or self.config.top_k
        _threshold = threshold if threshold is not None else self.config.threshold
        _mmr = mmr_enabled if mmr_enabled is not None else self.config.mmr_enabled
        _lambda = mmr_lambda or self.config.mmr_lambda

        t_start = time.perf_counter()

        # 1. Embed the query
        t_embed_start = time.perf_counter()
        query_vector = await self.embedder.embed_query(query)
        t_embed = time.perf_counter() - t_embed_start

        # 2. Build metadata filter conditions
        filter_conditions = self._build_filters(filters)

        # 3. Search the vector store
        prefetch_k = _top_k * self.config.prefetch_multiplier if _mmr else _top_k
        t_search_start = time.perf_counter()
        raw_results = await self.store.search(
            vector=query_vector,
            limit=prefetch_k,
            filter_conditions=filter_conditions,
        )
        t_search = time.perf_counter() - t_search_start

        # 4. Apply similarity threshold
        filtered = [r for r in raw_results if r.score >= _threshold]

        # 5. Apply MMR if enabled
        t_mmr_start = time.perf_counter()
        if _mmr and len(filtered) > _top_k:
            final_results = self._apply_mmr(
                query_vector, filtered, _top_k, _lambda)
        else:
            final_results = filtered[:_top_k]
        t_mmr = time.perf_counter() - t_mmr_start

        t_total = time.perf_counter() - t_start

        # 6. Build response
        search_results = [
            self._to_search_result(r) for r in final_results
        ]

        debug = None
        if include_debug:
            debug = SearchDebugInfo(
                query_text=query,
                query_tokens=self._count_tokens(query),
                embedding_latency_ms=int(t_embed * 1000),
                search_latency_ms=int(t_search * 1000),
                mmr_latency_ms=int(t_mmr * 1000),
                total_latency_ms=int(t_total * 1000),
                results_from_db=len(raw_results),
                results_after_threshold=len(filtered),
                results_after_filters=len(filtered),
                results_after_mmr=len(final_results),
            )

        return SemanticSearchResponse(
            query=query,
            results=search_results,
            total_results=len(final_results),
            debug=debug,
        )

    def _apply_mmr(
        self,
        query_vector: list[float],
        candidates: list,
        top_k: int,
        lambda_param: float,
    ) -> list:
        """Apply Maximal Marginal Relevance re-ranking."""
        query_vec = np.array(query_vector)
        candidate_vecs = np.array([c.vector for c in candidates])

        selected = []
        remaining = list(range(len(candidates)))

        for _ in range(min(top_k, len(candidates))):
            best_idx = None
            best_score = -float("inf")

            for idx in remaining:
                # Relevance to query
                relevance = candidates[idx].score

                # Max similarity to already-selected results
                if selected:
                    selected_vecs = candidate_vecs[selected]
                    sim_to_selected = np.max(
                        np.dot(selected_vecs, candidate_vecs[idx])
                        / (np.linalg.norm(selected_vecs, axis=1)
                           * np.linalg.norm(candidate_vecs[idx]))
                    )
                else:
                    sim_to_selected = 0.0

                mmr_score = (
                    lambda_param * relevance
                    - (1 - lambda_param) * sim_to_selected
                )

                if mmr_score > best_score:
                    best_score = mmr_score
                    best_idx = idx

            if best_idx is not None:
                selected.append(best_idx)
                remaining.remove(best_idx)

        return [candidates[i] for i in selected]

    def _build_filters(
        self, filters: MetadataFilters | None
    ) -> dict | None:
        """Build filter conditions for the vector store query."""
        active_filters = filters
        if active_filters is None and self.config.default_filters_enabled:
            active_filters = self.config.default_filters
        if active_filters is None:
            return None

        conditions = {}
        if active_filters.doc_ids:
            conditions["doc_id"] = {"$in": active_filters.doc_ids}
        if active_filters.doc_types:
            conditions["doc_type"] = {"$in": active_filters.doc_types}
        if active_filters.languages:
            conditions["doc_language"] = {"$in": active_filters.languages}
        if active_filters.categories:
            conditions["category"] = {"$in": active_filters.categories}

        return conditions if conditions else None
```

### 5.3 Extension du BaseVectorStore â€” mÃ©thode `search`

L'Ã‰tape 4 a dÃ©fini `BaseVectorStore` avec `upsert`, `delete_by_doc_id`, etc. L'Ã‰tape 5 **ajoute** la mÃ©thode `search` :

```python
# ragkit/storage/base.py â€” ajouts Ã‰tape 5

@dataclass
class SearchHit:
    """Raw result from a vector store search."""
    id: str
    score: float
    vector: list[float] | None    # Needed for MMR computation
    payload: dict


class BaseVectorStore(ABC):
    # ... (mÃ©thodes existantes Ã‰tape 4) ...

    @abstractmethod
    async def search(
        self,
        vector: list[float],
        limit: int = 10,
        filter_conditions: dict | None = None,
        with_vectors: bool = False,
    ) -> list[SearchHit]:
        """Search for nearest vectors. Returns results sorted by score desc."""
        ...

    @abstractmethod
    async def get_distinct_values(
        self, field_name: str
    ) -> list[str]:
        """Get distinct values for a payload field (for filter dropdowns)."""
        ...
```

**ImplÃ©mentation Qdrant** :

```python
# ragkit/storage/qdrant_store.py â€” mÃ©thode search

async def search(
    self,
    vector: list[float],
    limit: int = 10,
    filter_conditions: dict | None = None,
    with_vectors: bool = False,
) -> list[SearchHit]:
    """Search Qdrant collection by vector similarity."""
    from qdrant_client.models import Filter, FieldCondition, MatchAny

    qdrant_filter = None
    if filter_conditions:
        must_conditions = []
        for field, condition in filter_conditions.items():
            if "$in" in condition:
                must_conditions.append(
                    FieldCondition(
                        key=field,
                        match=MatchAny(any=condition["$in"]),
                    )
                )
        if must_conditions:
            qdrant_filter = Filter(must=must_conditions)

    results = self._client.search(
        collection_name=self.config.collection_name,
        query_vector=vector,
        limit=limit,
        query_filter=qdrant_filter,
        with_vectors=with_vectors,
        score_threshold=None,  # Threshold applied in engine
    )

    return [
        SearchHit(
            id=str(r.id),
            score=r.score,
            vector=r.vector if with_vectors else None,
            payload=r.payload or {},
        )
        for r in results
    ]
```

### 5.4 API REST (routes backend)

#### 5.4.1 Routes Recherche sÃ©mantique Config

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/retrieval/semantic/config` | GET | Config recherche sÃ©mantique courante | â€” | `SemanticSearchConfig` |
| `/api/retrieval/semantic/config` | PUT | Met Ã  jour la config | `SemanticSearchConfig` (partiel) | `SemanticSearchConfig` |
| `/api/retrieval/semantic/config/reset` | POST | RÃ©initialise au profil actif | â€” | `SemanticSearchConfig` |

#### 5.4.2 Routes Recherche

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/search/semantic` | POST | ExÃ©cute une recherche sÃ©mantique | `SearchQuery` | `SemanticSearchResponse` |
| `/api/search/filters/values` | GET | Valeurs disponibles pour les filtres | `?field=doc_type` | `{ values: string[] }` |

#### 5.4.3 Routes Chat

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/chat/ready` | GET | VÃ©rifie si le chat est prÃªt (index non vide) | â€” | `{ ready: bool, vectors_count: int }` |

#### 5.4.4 ModÃ¨les de requÃªte et rÃ©ponse

```python
class SearchQuery(BaseModel):
    """Search query from the chat interface."""
    query: str = Field(..., min_length=1, max_length=2000)
    top_k: int | None = None              # Override config default
    threshold: float | None = None        # Override config default
    filters: SearchFilters | None = None  # Runtime filters from chat
    mmr_enabled: bool | None = None       # Override config default
    mmr_lambda: float | None = None       # Override config default
    include_debug: bool = False
    page: int = Field(default=1, ge=1)
    page_size: int = Field(default=5, ge=1, le=50)

class SearchFilters(BaseModel):
    """Runtime filters from the chat interface."""
    doc_ids: list[str] | None = None
    doc_types: list[str] | None = None
    languages: list[str] | None = None
    categories: list[str] | None = None

class SemanticSearchResponse(BaseModel):
    query: str
    results: list[SearchResultItem]
    total_results: int
    page: int
    page_size: int
    has_more: bool
    debug: SearchDebugInfo | None = None

class SearchResultItem(BaseModel):
    chunk_id: str
    score: float
    text: str
    text_preview: str             # TronquÃ© Ã  300 caractÃ¨res
    doc_title: str | None
    doc_path: str | None
    doc_type: str | None
    page_number: int | None
    chunk_index: int | None
    chunk_total: int | None
    chunk_tokens: int | None
    section_header: str | None
    doc_language: str | None
    category: str | None
    keywords: list[str]
    ingestion_version: str | None

class SearchDebugInfo(BaseModel):
    query_text: str
    query_tokens: int
    embedding_latency_ms: int
    search_latency_ms: int
    mmr_latency_ms: int
    total_latency_ms: int
    results_from_db: int
    results_after_threshold: int
    results_after_filters: int
    results_after_mmr: int
```

### 5.5 Commandes Tauri (Rust) â€” ajouts

```rust
// desktop/src-tauri/src/commands.rs (ajouts Ã‰tape 5)

// Retrieval config
#[tauri::command]
pub async fn get_semantic_search_config() -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn update_semantic_search_config(config: serde_json::Value) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn reset_semantic_search_config() -> Result<serde_json::Value, String> { ... }

// Search
#[tauri::command]
pub async fn semantic_search(query: serde_json::Value) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn get_filter_values(field: String) -> Result<serde_json::Value, String> { ... }

// Chat readiness
#[tauri::command]
pub async fn is_chat_ready() -> Result<serde_json::Value, String> { ... }
```

### 5.6 Composants React â€” arborescence

```
desktop/src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â”œâ”€â”€ SemanticSearchSettings.tsx         â† NOUVEAU : section complÃ¨te
â”‚   â”‚   â”œâ”€â”€ MMRPanel.tsx                       â† NOUVEAU : paramÃ¨tres de diversification
â”‚   â”‚   â”œâ”€â”€ MetadataFiltersConfig.tsx          â† NOUVEAU : filtres par dÃ©faut
â”‚   â”‚   â””â”€â”€ ... (existants)
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ ChatView.tsx                       â† MODIFIER : activer (plus de placeholder)
â”‚   â”‚   â”œâ”€â”€ SearchBar.tsx                      â† NOUVEAU : barre de recherche
â”‚   â”‚   â”œâ”€â”€ FilterBar.tsx                      â† NOUVEAU : filtres rapides (dropdowns)
â”‚   â”‚   â”œâ”€â”€ SearchResults.tsx                  â† NOUVEAU : liste des rÃ©sultats
â”‚   â”‚   â”œâ”€â”€ SearchResultCard.tsx               â† NOUVEAU : carte d'un rÃ©sultat
â”‚   â”‚   â”œâ”€â”€ SearchResultDetail.tsx             â† NOUVEAU : dÃ©tail dÃ©pliÃ© d'un rÃ©sultat
â”‚   â”‚   â”œâ”€â”€ SearchDebugPanel.tsx               â† NOUVEAU : panneau debug
â”‚   â”‚   â”œâ”€â”€ ChatOptions.tsx                    â† NOUVEAU : bouton âš™ Options
â”‚   â”‚   â”œâ”€â”€ EmptyIndex.tsx                     â† NOUVEAU : placeholder index vide
â”‚   â”‚   â””â”€â”€ ScoreBadge.tsx                     â† NOUVEAU : badge score avec couleur
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ HighlightedText.tsx                â† NOUVEAU : surlignage de la requÃªte
â”‚       â”œâ”€â”€ MultiSelect.tsx                    â† NOUVEAU : sÃ©lecteur multi-valeurs
â”‚       â””â”€â”€ ... (existants)
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useSemanticSearchConfig.ts             â† NOUVEAU : hook config
â”‚   â”œâ”€â”€ useSemanticSearch.ts                   â† NOUVEAU : hook exÃ©cution recherche
â”‚   â”œâ”€â”€ useFilterValues.ts                     â† NOUVEAU : hook valeurs de filtres
â”‚   â”œâ”€â”€ useChatReady.ts                        â† NOUVEAU : hook Ã©tat du chat
â”‚   â””â”€â”€ ... (existants)
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ipc.ts                                 â† MODIFIER : ajouter routes search + chat
â””â”€â”€ locales/
    â”œâ”€â”€ fr.json                                â† MODIFIER : ajouter clÃ©s chat + search
    â””â”€â”€ en.json                                â† MODIFIER : ajouter clÃ©s chat + search
```

### 5.7 DÃ©tail du composant `SearchResultCard.tsx`

```tsx
interface SearchResultCardProps {
  result: SearchResultItem;
  query: string;
  rank: number;
  showScore: boolean;
  showMetadata: boolean;
}

export function SearchResultCard({
  result, query, rank, showScore, showMetadata
}: SearchResultCardProps) {
  const [expanded, setExpanded] = useState(false);

  return (
    <div
      className="border rounded-lg p-4 cursor-pointer hover:bg-gray-50"
      onClick={() => setExpanded(!expanded)}
    >
      <div className="flex justify-between items-start">
        <div className="flex items-center gap-2 text-sm text-gray-500">
          <span>ğŸ“„ {result.doc_title || result.doc_path}</span>
          {result.page_number && <span>Â· Page {result.page_number}</span>}
        </div>
        {showScore && (
          <ScoreBadge score={result.score} />
        )}
      </div>

      <div className="mt-2">
        <HighlightedText
          text={expanded ? result.text : result.text_preview}
          query={query}
        />
      </div>

      {showMetadata && (
        <div className="mt-2 flex gap-3 text-xs text-gray-400">
          {result.category && <span>ğŸ“ {result.category}</span>}
          {result.keywords.length > 0 && (
            <span>ğŸ· {result.keywords.join(", ")}</span>
          )}
          {result.doc_language && <span>ğŸŒ {result.doc_language}</span>}
        </div>
      )}

      {expanded && (
        <SearchResultDetail result={result} />
      )}
    </div>
  );
}
```

### 5.8 Persistance

La config de recherche sÃ©mantique est stockÃ©e dans `settings.json` :

```json
{
  "version": "1.0.0",
  "ingestion": { "...": "..." },
  "chunking": { "...": "..." },
  "embedding": { "...": "..." },
  "vector_store": { "...": "..." },
  "general": { "...": "..." },
  "retrieval": {
    "architecture": "hybrid_rerank",
    "semantic": {
      "enabled": true,
      "top_k": 15,
      "threshold": 0.0,
      "weight": 0.5,
      "mmr_enabled": false,
      "mmr_lambda": 0.5,
      "default_filters_enabled": false,
      "default_filters": {
        "doc_ids": [],
        "doc_types": [],
        "languages": [],
        "categories": []
      },
      "prefetch_multiplier": 3,
      "debug_default": false
    },
    "lexical": { "...": "valeurs stockÃ©es, utilisÃ©es Ã  l'Ã‰tape 6" },
    "hybrid": { "...": "valeurs stockÃ©es, utilisÃ©es Ã  l'Ã‰tape 7" }
  }
}
```

### 5.9 DÃ©pendances Python ajoutÃ©es

```toml
# pyproject.toml â€” ajouts aux dependencies pour Ã‰tape 5
dependencies = [
    # ... (existants Ã‰tapes 0-4)
    # numpy est dÃ©jÃ  prÃ©sent (Ã‰tape 3)
    # Aucune nouvelle dÃ©pendance Python requise pour cette Ã©tape.
    # La recherche sÃ©mantique utilise :
    # - qdrant-client / chromadb (Ã‰tape 4) pour la requÃªte vectorielle
    # - numpy (Ã‰tape 3) pour le calcul MMR
    # - L'embedding provider (Ã‰tape 3) pour vectoriser la requÃªte
]
```

---

## 6. CritÃ¨res d'acceptation

### 6.1 Fonctionnels

| # | CritÃ¨re |
|---|---------|
| F1 | La section `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > RECHERCHE SÃ‰MANTIQUE` est accessible et affiche tous les paramÃ¨tres |
| F2 | Le toggle `enabled` active/dÃ©sactive la recherche sÃ©mantique |
| F3 | Le slider `top_k` modifie le nombre de rÃ©sultats retournÃ©s |
| F4 | Le slider `threshold` filtre les rÃ©sultats en dessous du seuil |
| F5 | Le toggle MMR active la diversification des rÃ©sultats |
| F6 | Le slider `mmr_lambda` ajuste la balance pertinence/diversitÃ© |
| F7 | La section "Filtres par mÃ©tadonnÃ©es" permet de configurer des filtres par dÃ©faut |
| F8 | L'onglet CHAT est activÃ© et fonctionnel quand l'index contient des vecteurs |
| F9 | L'onglet CHAT affiche un placeholder "Base vide" si aucune ingestion n'a Ã©tÃ© faite |
| F10 | La barre de recherche accepte une requÃªte texte et dÃ©clenche la recherche |
| F11 | Les rÃ©sultats s'affichent sous forme de cartes avec score, source, extrait, mÃ©tadonnÃ©es |
| F12 | Le score de chaque rÃ©sultat est affichÃ© avec un code couleur (vert â†’ rouge) |
| F13 | Le texte de la requÃªte est surlignÃ© dans les extraits des rÃ©sultats |
| F14 | Cliquer sur un rÃ©sultat dÃ©ploie le texte complet et les mÃ©tadonnÃ©es dÃ©taillÃ©es |
| F15 | Les filtres rapides (documents, langues, types, catÃ©gories) fonctionnent dans le chat |
| F16 | Les listes de filtres sont dynamiquement chargÃ©es depuis l'index |
| F17 | Le mode debug affiche les latences et compteurs de rÃ©sultats |
| F18 | Le bouton "âš™ Options" permet de toggler debug, scores, mÃ©tadonnÃ©es |
| F19 | La pagination "Voir plus de rÃ©sultats" charge les rÃ©sultats suivants |
| F20 | Le badge "ModifiÃ©" apparaÃ®t Ã  cÃ´tÃ© de chaque paramÃ¨tre modifiÃ© |
| F21 | Le bouton "RÃ©initialiser au profil" restaure les valeurs par dÃ©faut |
| F22 | Tous les textes sont traduits FR/EN via i18n |

### 6.2 Techniques

| # | CritÃ¨re |
|---|---------|
| T1 | `GET /api/retrieval/semantic/config` retourne la config courante |
| T2 | `PUT /api/retrieval/semantic/config` valide et persiste les modifications |
| T3 | `POST /api/retrieval/semantic/config/reset` restaure les valeurs du profil actif |
| T4 | `POST /api/search/semantic` retourne les rÃ©sultats de la recherche vectorielle |
| T5 | La requÃªte est vectorisÃ©e via le modÃ¨le d'embedding configurÃ© (Ã‰tape 3) |
| T6 | Le seuil de similaritÃ© filtre correctement les rÃ©sultats |
| T7 | Le filtrage par mÃ©tadonnÃ©es fonctionne pour chaque champ (doc_type, language, category, doc_id) |
| T8 | L'algorithme MMR produit des rÃ©sultats diversifiÃ©s (vÃ©rifiable : les rÃ©sultats MMR ont une similaritÃ© inter-rÃ©sultat infÃ©rieure aux rÃ©sultats bruts) |
| T9 | La recherche fonctionne avec Qdrant |
| T10 | La recherche fonctionne avec ChromaDB |
| T11 | `GET /api/search/filters/values?field=doc_type` retourne les valeurs distinctes du champ |
| T12 | `GET /api/chat/ready` retourne `{ ready: true }` quand l'index contient des vecteurs |
| T13 | La latence totale d'une recherche est infÃ©rieure Ã  500 ms pour un index de 10K vecteurs |
| T14 | La pagination retourne les rÃ©sultats corrects (page 1 = rÃ©sultats 1-5, page 2 = 6-10, etc.) |
| T15 | La config recherche sÃ©mantique est persistÃ©e dans `settings.json` sous `retrieval.semantic` |
| T16 | `tsc --noEmit` ne produit aucune erreur TypeScript |
| T17 | Le CI passe sur les 4 targets (lint + build) |

---

## 7. PÃ©rimÃ¨tre exclus (Ã‰tape 5)

- **Recherche lexicale (BM25)** : sera ajoutÃ©e Ã  l'Ã‰tape 6.
- **Recherche hybride** (fusion sÃ©mantique + lexicale) : sera ajoutÃ©e Ã  l'Ã‰tape 7.
- **Reranking** : sera ajoutÃ© Ã  l'Ã‰tape 8.
- **GÃ©nÃ©ration LLM** : sera ajoutÃ©e Ã  l'Ã‰tape 9. Le chat affiche uniquement les rÃ©sultats bruts.
- **Historique de conversation** : pas de mÃ©moire de conversation Ã  cette Ã©tape. Chaque requÃªte est indÃ©pendante.
- **Query expansion** (synonymes, reformulation) : sera ajoutÃ©e Ã  l'Ã‰tape 10 (Agents).
- **HyDE** (Hypothetical Document Embeddings) : amÃ©lioration future.
- **Multi-query** (gÃ©nÃ©ration de requÃªtes multiples) : sera ajoutÃ©e Ã  l'Ã‰tape 10 (Agents).
- **SÃ©lecteur de mode de recherche** dans le chat : sera ajoutÃ© Ã  l'Ã‰tape 6 (quand le second mode sera disponible).

---

## 8. Estimation

| TÃ¢che | Effort estimÃ© |
|-------|---------------|
| SchÃ©ma Pydantic `SemanticSearchConfig` + validation | 0.5 jour |
| `SemanticSearchEngine` (recherche + MMR + filtres + debug) | 2 jours |
| Extension `BaseVectorStore.search()` + `get_distinct_values()` | 0.5 jour |
| ImplÃ©mentation `QdrantVectorStore.search()` avec filtrage | 1 jour |
| ImplÃ©mentation `ChromaVectorStore.search()` avec filtrage | 0.5 jour |
| Routes API config (CRUD) | 0.5 jour |
| Routes API recherche (`/api/search/semantic`, `/api/search/filters/values`) | 1 jour |
| Route `/api/chat/ready` | 0.5 jour |
| Commandes Tauri (Rust) | 0.5 jour |
| Composant `SemanticSearchSettings.tsx` (section paramÃ¨tres) | 1 jour |
| Composant `MMRPanel.tsx` + `MetadataFiltersConfig.tsx` | 0.5 jour |
| Composant `ChatView.tsx` (activation + layout) | 0.5 jour |
| Composant `SearchBar.tsx` + `FilterBar.tsx` | 1 jour |
| Composant `SearchResults.tsx` + `SearchResultCard.tsx` | 1.5 jours |
| Composant `SearchResultDetail.tsx` (vue dÃ©taillÃ©e dÃ©ployable) | 0.5 jour |
| Composant `SearchDebugPanel.tsx` | 0.5 jour |
| Composant `ChatOptions.tsx` (panneau Options) | 0.5 jour |
| Composants UI (`ScoreBadge`, `HighlightedText`, `MultiSelect`, `EmptyIndex`) | 1 jour |
| Hooks (`useSemanticSearch`, `useSemanticSearchConfig`, `useFilterValues`, `useChatReady`) | 1 jour |
| Traductions i18n (FR + EN) â€” chat + recherche | 0.5 jour |
| Tests unitaires `SemanticSearchEngine` (recherche, MMR, filtres, seuil) | 1.5 jours |
| Tests unitaires `search()` pour Qdrant et ChromaDB | 1 jour |
| Tests d'intÃ©gration (pipeline complet : requÃªte â†’ embedding â†’ recherche â†’ rÃ©sultats) | 1 jour |
| Tests manuels + corrections | 1 jour |
| **Total** | **~19 jours** |
