# üß∞ RAGKIT ‚Äî Plan de D√©veloppement Incr√©mental

> **Version** : 2.0  
> **Date** : 13 f√©vrier 2026  
> **Objectif** : D√©crire le plan de refonte compl√®te de RAGKIT, √©tape par √©tape, avec des releases interm√©diaires fonctionnelles.

---

## Principes directeurs

- **Chaque √©tape produit un livrable utilisable** : l'application est testable et distribuable √† la fin de chaque √©tape.
- **Les param√®tres sont toujours pilot√©s par le profilage initial** : le wizard de l'√âtape 1 d√©termine les valeurs par d√©faut de toutes les √©tapes suivantes.
- **L'utilisateur peut tout modifier** : chaque param√®tre par d√©faut est √©ditable dans `PARAM√àTRES > Param√®tres avanc√©s > [section]`.
- **La complexit√© est progressive** : l'utilisateur d√©butant ne voit que le wizard et les param√®tres g√©n√©raux ; l'expert peut tout r√©gler dans les param√®tres avanc√©s.

---

## Vue d'ensemble des √©tapes

```
√âtape 0 ‚îÄ Ossature & Release 0             ‚Üí .exe avec coquille vide
√âtape 1 ‚îÄ Ingestion & Pr√©processing        ‚Üí Wizard + analyse des documents
√âtape 2 ‚îÄ Chunking                          ‚Üí D√©coupage param√©trable
√âtape 3 ‚îÄ Embedding                         ‚Üí Vectorisation des chunks
√âtape 4 ‚îÄ Base de donn√©es vectorielle       ‚Üí Stockage + pipeline d'ingestion complet
√âtape 5 ‚îÄ Recherche s√©mantique             ‚Üí Premier agent de recherche
√âtape 6 ‚îÄ Recherche lexicale (BM25)        ‚Üí Deuxi√®me mode de recherche
√âtape 7 ‚îÄ Recherche hybride                ‚Üí Fusion des deux recherches
√âtape 8 ‚îÄ Reranking                         ‚Üí R√©ordonnancement des r√©sultats
√âtape 9 ‚îÄ LLM / G√©n√©ration                 ‚Üí R√©ponse finale en langage naturel
√âtape 10 ‚îÄ Agents & Orchestration           ‚Üí Query Analyzer + Orchestrateur complet
√âtape 11 ‚îÄ Monitoring & √âvaluation          ‚Üí Tableau de bord avanc√© + m√©triques
√âtape 12 ‚îÄ S√©curit√©, UX & Finalisation     ‚Üí Polish, s√©curit√©, export
```

---

## √âtape 0 ‚Äî Ossature & Release 0

### üéØ Objectif

Mettre en place le socle technique de l'application et livrer un premier `.exe` installable qui prouve que la cha√Æne de build fonctionne de bout en bout.

### Fonctionnalit√©s

1. **Structure projet** : initialiser le monorepo avec le backend Python (FastAPI), le frontend desktop (Electron/Tauri + React) et le syst√®me de build.
2. **Application desktop** : fen√™tre principale avec navigation entre trois onglets vides :
   - **CHAT** ‚Äî placeholder "Le chat sera disponible apr√®s configuration."
   - **PARAM√àTRES** ‚Äî placeholder "Configurez votre RAG ici."
   - **TABLEAU DE BORD** ‚Äî placeholder "Le monitoring appara√Ætra ici."
3. **Build & distribution** : pipeline de build produisant un installeur `.exe` Windows sign√©.
4. **Internationalisation** : infrastructure i18n en place (FR par d√©faut, EN pr√™t).
5. **Th√®me clair/sombre** : toggle fonctionnel d√®s cette √©tape.

### Sortie attendue

> L'utilisateur t√©l√©charge et installe le `.exe`. L'application s'ouvre et affiche le nom "RAGKIT" avec les trois onglets vides navigables. Aucune fonctionnalit√© m√©tier.

---

## √âtape 1 ‚Äî Ingestion & Pr√©processing

### üéØ Objectif

Permettre √† l'utilisateur de configurer sa base de connaissances via un assistant guid√© (wizard) et d'analyser ses documents pour en extraire les m√©tadonn√©es. C'est le **point d'entr√©e de toute l'exp√©rience utilisateur**.

### Fonctionnalit√©s

#### 1.1 ‚Äî Wizard de configuration initiale

Au premier lancement (aucune configuration d√©tect√©e), le wizard se d√©clenche automatiquement et guide l'utilisateur en s√©quence :

**√âcran 1 ‚Äî Bienvenue**
- Pr√©sentation de RAGKIT, de ses capacit√©s, et du processus de configuration.
- Bouton "Commencer la configuration ‚Üí".

**√âcran 2 ‚Äî Profilage de la base de connaissances**
- **Question principale** : "Quel type de contenu d√©crit le mieux votre base ?" avec les profils :
  - üìò Documentation technique
  - ‚ùì FAQ / Support
  - üìú Juridique / R√©glementaire
  - üìä Rapports & Analyses
  - üìö Base g√©n√©raliste
- **6 questions de calibrage** (Oui/Non) pour affiner le profil :

| # | Question | Impact si OUI |
|---|----------|---------------|
| 1 | Documents avec tableaux ou sch√©mas ? | Parsing avanc√© (tables, OCR) |
| 2 | R√©ponses croisant plusieurs documents ? | Multi-doc retrieval, `top_k` augment√© |
| 3 | Documents de plus de 50 pages en moyenne ? | Chunks plus grands, chunking hi√©rarchique |
| 4 | Besoin de r√©ponses tr√®s pr√©cises (chiffres, dates) ? | Reranking activ√©, temp√©rature LLM basse |
| 5 | Base mise √† jour fr√©quemment ? | Mode watch / ingestion incr√©mentale |
| 6 | Citations avec sources et num√©ros de page ? | M√©tadonn√©es de source activ√©es |

- **R√©sultat** : affichage du profil d√©tect√© avec un r√©capitulatif des param√®tres par d√©faut qui en d√©coulent. L'utilisateur peut accepter ou modifier manuellement.

**√âcran 3 ‚Äî S√©lection du r√©pertoire de documents**
- Bouton "Parcourir‚Ä¶" ou glisser-d√©poser d'un dossier.
- **Inclusion des sous-dossiers** : choix Oui/Non.
  - Si OUI : affichage de l'arborescence compl√®te avec tous les sous-dossiers coch√©s par d√©faut. L'utilisateur peut d√©cocher ceux qu'il souhaite exclure.
- **Patterns d'exclusion avanc√©s** (optionnel, section d√©pliable) : ex. `*_draft.*`, `*_old.*`, fichiers > X Mo.

**√âcran 4 ‚Äî S√©lection des types de documents**
- L'application scanne le r√©pertoire s√©lectionn√© (et les sous-dossiers retenus).
- Affichage de tous les types de fichiers trouv√©s (PDF, DOCX, MD, TXT, HTML, CSV, etc.) avec le nombre de fichiers par type.
- Les types support√©s par RAGKIT sont coch√©s par d√©faut. Les types non support√©s sont gris√©s avec une info-bulle explicative.
- L'utilisateur peut d√©cocher des types s'il souhaite en exclure certains.

#### 1.2 ‚Äî Analyse des documents et m√©tadonn√©es

- L'outil parcourt les documents retenus et extrait les **m√©tadonn√©es techniques** (taille, nombre de pages, langue d√©tect√©e, format, date de modification) et les **m√©tadonn√©es fonctionnelles** (titre d√©tect√©, auteur si disponible, r√©sum√©/description, mots-cl√©s).
- Les m√©tadonn√©es fonctionnelles sont affich√©es √† l'utilisateur dans un tableau √©ditable pour validation ou correction.
- Une fois valid√©es, l'utilisateur est dirig√© vers `PARAM√àTRES > Param√®tres avanc√©s > INGESTION & PR√âPROCESSING`.

#### 1.3 ‚Äî Onglet PARAM√àTRES > Param√®tres avanc√©s > INGESTION & PR√âPROCESSING

Tous les param√®tres issus du wizard et de l'analyse sont visibles et modifiables :

- **Document Parsing** : `document_loader_type`, `ocr_enabled`, `ocr_language`, `ocr_engine`, `table_extraction_strategy`, `image_captioning_enabled`, `header_detection`.
- **Text Preprocessing** : `lowercase`, `remove_punctuation`, `normalize_unicode`, `remove_urls`, `language_detection`, `deduplication_strategy`, `deduplication_threshold`.
- **Source** : chemin du r√©pertoire, r√©cursivit√©, sous-dossiers exclus, patterns de fichiers, patterns d'exclusion.
- **M√©tadonn√©es** : tableau des m√©tadonn√©es fonctionnelles valid√©es.

#### 1.4 ‚Äî Structure de l'onglet PARAM√àTRES √† cette √©tape

```
PARAM√àTRES
‚îú‚îÄ‚îÄ Param√®tres g√©n√©raux          ‚Üê (vide pour l'instant)
‚îî‚îÄ‚îÄ Param√®tres avanc√©s
    ‚îî‚îÄ‚îÄ INGESTION & PR√âPROCESSING
```

### Sortie attendue

> L'utilisateur lance l'application, passe par le wizard, s√©lectionne son dossier de documents, voit l'analyse des fichiers avec m√©tadonn√©es, valide, et retrouve tous les param√®tres d'ingestion dans l'onglet d√©di√©. Le pipeline de parsing est fonctionnel mais n'indexe pas encore (pas de chunking ni embedding).

---

## √âtape 2 ‚Äî Chunking

### üéØ Objectif

Ajouter le d√©coupage intelligent des documents en chunks, param√©trable selon la strat√©gie choisie lors du profilage.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > CHUNKING`.
2. **Param√®tres expos√©s** (valeurs par d√©faut issues du profilage) :
   - `chunking_strategy` : `fixed_size` | `sentence_based` | `paragraph_based` | `semantic` | `recursive` | `markdown_header`
   - `chunk_size` : taille en tokens (ex : 256, 512, 1024)
   - `chunk_overlap` : chevauchement en tokens (ex : 50, 100, 200)
   - `min_chunk_size` : taille minimale d'un chunk (√©viter les micro-chunks)
   - `max_chunk_size` : taille maximale
   - Pour la strat√©gie `semantic` : `similarity_threshold`, mod√®le utilis√©
   - `separators` : liste des s√©parateurs utilis√©s (pour strat√©gie r√©cursive)
   - `preserve_sentences` : ne pas couper au milieu d'une phrase (bool√©en)
   - `metadata_propagation` : propager les m√©tadonn√©es du document parent aux chunks
3. **Pr√©visualisation** : possibilit√© de voir un aper√ßu du d√©coupage sur un document-√©chantillon directement depuis l'interface des param√®tres (bouton "Pr√©visualiser le chunking").
4. Modification des param√®tres ‚Üí prise en compte imm√©diate (mais ingestion non encore possible, car pas d'embedding).

### Structure PARAM√àTRES √† cette √©tape

```
PARAM√àTRES
‚îú‚îÄ‚îÄ Param√®tres g√©n√©raux          ‚Üê (vide)
‚îî‚îÄ‚îÄ Param√®tres avanc√©s
    ‚îú‚îÄ‚îÄ INGESTION & PR√âPROCESSING
    ‚îî‚îÄ‚îÄ CHUNKING
```

### Sortie attendue

> L'utilisateur peut configurer la strat√©gie de chunking et pr√©visualiser le r√©sultat sur un document-√©chantillon. Le pipeline parsing ‚Üí chunking est fonctionnel en interne.

---

## √âtape 3 ‚Äî Embedding

### üéØ Objectif

Ajouter la vectorisation des chunks via des mod√®les d'embedding configurables (local ou API cloud).

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > EMBEDDING`.
2. **Param√®tres expos√©s** :
   - **Mod√®le document** : `provider` (openai | ollama | huggingface | cohere | voyageai | mistral), `model`, `api_key`
   - **Mod√®le requ√™te** : possibilit√© d'utiliser un mod√®le diff√©rent pour l'embedding des requ√™tes (ou cocher "Identique au mod√®le document")
   - `batch_size` : nombre de textes par requ√™te d'embedding
   - `dimensions` : dimensions du vecteur (si configurable par le mod√®le)
   - `cache_enabled` : mise en cache des embeddings (bool√©en)
   - `cache_backend` : `memory` | `disk`
   - `normalize_embeddings` : normalisation L2 des vecteurs
3. **D√©tection environnement** (si pas d√©j√† fait au wizard) : d√©tection GPU, Ollama install√©, mod√®les locaux disponibles.
4. **Test de connexion** : bouton pour valider que le provider est joignable et le mod√®le fonctionnel.

### Structure PARAM√àTRES √† cette √©tape

```
PARAM√àTRES
‚îú‚îÄ‚îÄ Param√®tres g√©n√©raux          ‚Üê (vide)
‚îî‚îÄ‚îÄ Param√®tres avanc√©s
    ‚îú‚îÄ‚îÄ INGESTION & PR√âPROCESSING
    ‚îú‚îÄ‚îÄ CHUNKING
    ‚îî‚îÄ‚îÄ EMBEDDING
```

### Sortie attendue

> L'utilisateur peut configurer et tester son mod√®le d'embedding. Le pipeline parsing ‚Üí chunking ‚Üí embedding est fonctionnel en interne, mais les vecteurs ne sont pas encore stock√©s.

---

## √âtape 4 ‚Äî Base de donn√©es vectorielle

### üéØ Objectif

Ajouter le stockage vectoriel, compl√©ter le pipeline d'ingestion de bout en bout, et permettre √† l'utilisateur de lancer et monitorer l'ingestion depuis le tableau de bord.

### Fonctionnalit√©s

#### 4.1 ‚Äî Param√®tres de la base vectorielle

- **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > BASE DE DONN√âES VECTORIELLE`.
- **Param√®tres** :
  - `provider` : `qdrant` | `chroma`
  - `mode` : `memory` | `persistent`
  - `path` : chemin de stockage (mode persistent)
  - `collection_name` : nom de la collection
  - `distance_metric` : `cosine` | `euclidean` | `dot`
  - `index_type` : type d'index (HNSW, etc.)
  - Param√®tres HNSW : `ef_construction`, `m`

#### 4.2 ‚Äî Pipeline d'ingestion complet

Le pipeline complet est maintenant op√©rationnel : **Parsing ‚Üí Chunking ‚Üí Embedding ‚Üí Stockage vectoriel**.

#### 4.3 ‚Äî Gestion de l'ingestion

- **Lancement** : bouton "Lancer l'ingestion" dans le `TABLEAU DE BORD`.
- **Monitoring temps r√©el** dans le `TABLEAU DE BORD` :
  - Barre de progression (X/Y documents, pourcentage)
  - Temps √©coul√© et estimation du temps restant
  - Document en cours de traitement
  - Compteurs : r√©ussis / avertissements / √©checs
  - Boutons Pause et Annuler
- **D√©tection de changements** : l'application surveille le r√©pertoire source et signale dans le tableau de bord si des documents ont √©t√© ajout√©s, modifi√©s ou supprim√©s depuis la derni√®re ingestion.

#### 4.4 ‚Äî Mode d'ingestion (Param√®tres g√©n√©raux)

Ajout dans `PARAM√àTRES > Param√®tres g√©n√©raux` :

| Param√®tre | Description | Options |
|-----------|-------------|---------|
| Mode d'ingestion | Comment les changements sont pris en compte | **Manuel** : l'utilisateur lance l'ingestion lui-m√™me / **Automatique** : l'ingestion se relance automatiquement √† chaque mouvement dans la base de connaissances |

#### 4.5 ‚Äî Persistance et versioning de l'ingestion

- **Persistance** : l'ingestion pr√©c√©dente reste active et utilisable tant que la nouvelle n'est pas termin√©e. L'application ne bloque jamais l'utilisateur pendant une ingestion.
- **Ingestion incr√©mentale** : seuls les documents ajout√©s/modifi√©s sont r√©ing√©r√©s (strat√©gie `upsert`). Les documents supprim√©s sont retir√©s de l'index.
- **Versioning** : chaque ingestion cr√©e une version horodat√©e. L'utilisateur peut :
  - Voir l'historique des ingestions (date, nombre de docs/chunks, dur√©e, statut)
  - Revenir √† une version pr√©c√©dente (rollback)

#### 4.6 ‚Äî Notification de r√©ingestion

Si l'utilisateur modifie des param√®tres d'ingestion (parsing, chunking, embedding, BDD vectorielle), l'application affiche un avertissement :

> ‚ö†Ô∏è Modifier ce param√®tre n√©cessite une r√©ingestion compl√®te. Souhaitez-vous continuer ?

### Structure PARAM√àTRES √† cette √©tape

```
PARAM√àTRES
‚îú‚îÄ‚îÄ Param√®tres g√©n√©raux
‚îÇ   ‚îî‚îÄ‚îÄ Mode d'ingestion (Manuel / Automatique)
‚îî‚îÄ‚îÄ Param√®tres avanc√©s
    ‚îú‚îÄ‚îÄ INGESTION & PR√âPROCESSING
    ‚îú‚îÄ‚îÄ CHUNKING
    ‚îú‚îÄ‚îÄ EMBEDDING
    ‚îî‚îÄ‚îÄ BASE DE DONN√âES VECTORIELLE
```

### Sortie attendue

> L'utilisateur peut lancer l'ingestion compl√®te de ses documents. Le tableau de bord affiche la progression en temps r√©el et l'historique. L'ingestion est persistante et versionnable. L'application signale les changements dans la base de connaissances.

---

## √âtape 5 ‚Äî Recherche s√©mantique

### üéØ Objectif

Ajouter le premier mode de recherche fonctionnel : la recherche s√©mantique (par similarit√© vectorielle). L'utilisateur peut soumettre une requ√™te et voir les chunks les plus pertinents.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > RECHERCHE S√âMANTIQUE`.
2. **Param√®tres** :
   - `enabled` : activ√©e par d√©faut (bool√©en)
   - `top_k` : nombre de r√©sultats retourn√©s (ex : 10, 20)
   - `similarity_threshold` : score minimum de similarit√© (0.0 √† 1.0, 0 = pas de filtre)
   - `weight` : poids de cette recherche dans le score final (utilis√© plus tard pour la recherche hybride)
3. **Agent de recherche s√©mantique** :
   - Interface dans l'onglet **CHAT** : un champ de requ√™te simple.
   - L'utilisateur saisit une question ‚Üí l'application effectue une recherche s√©mantique ‚Üí affichage des r√©sultats.
   - **Affichage des r√©sultats** dans le chat : liste des chunks pertinents avec pour chacun :
     - Score de similarit√©
     - Contenu du chunk (extrait)
     - Source (nom du document, page si disponible)
     - M√©tadonn√©es associ√©es
   - Pas de g√©n√©ration LLM √† cette √©tape : uniquement les r√©sultats bruts de la recherche.

### Sortie attendue

> L'utilisateur peut taper une requ√™te dans le chat et voir les chunks les plus proches s√©mantiquement, avec scores et sources. C'est un premier outil de validation de la qualit√© de l'ingestion.

---

## √âtape 6 ‚Äî Recherche lexicale (BM25)

### üéØ Objectif

Ajouter un second mode de recherche bas√© sur la correspondance lexicale (BM25), compl√©mentaire √† la recherche s√©mantique.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > RECHERCHE LEXICALE`.
2. **Param√®tres** :
   - `enabled` : activ√©e par d√©faut (bool√©en)
   - `algorithm` : `bm25` | `bm25+`
   - `k1` : saturation du terme (1.2‚Äì2.0, d√©faut 1.5)
   - `b` : normalisation de longueur (0.5‚Äì0.8, d√©faut 0.75)
   - `top_k` : nombre de r√©sultats
   - `weight` : poids dans le score final
   - **Preprocessing lexical** : `lowercase`, `remove_stopwords`, `stopwords_lang` (french | english | auto), `stemming`
3. **Agent de recherche lexicale** :
   - M√™me interface dans le **CHAT**, mais l'utilisateur peut choisir le mode de recherche (s√©mantique ou lexicale) via un s√©lecteur.
   - Affichage des r√©sultats identique √† l'√âtape 5 (chunks, scores BM25, sources).

### Sortie attendue

> L'utilisateur peut basculer entre recherche s√©mantique et lexicale dans le chat et comparer les r√©sultats sur une m√™me requ√™te. Utile pour les cas o√π les termes exacts comptent (codes, r√©f√©rences, noms propres).

---

## √âtape 7 ‚Äî Recherche hybride

### üéØ Objectif

Fusionner les recherches s√©mantique et lexicale en une recherche hybride param√©trable, offrant le meilleur des deux approches.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > RECHERCHE HYBRIDE`.
2. **Param√®tres** :
   - `fusion_method` : `weighted_sum` | `reciprocal_rank_fusion` (RRF)
   - `alpha` : balance s√©mantique/lexical (0 = 100% lexical, 1 = 100% s√©mantique). Valeur par d√©faut issue du profilage.
   - `normalize_scores` : normalisation des scores avant fusion (bool√©en)
   - `rrf_k` : constante RRF (d√©faut 60)
3. **Ajout dans Param√®tres g√©n√©raux** :

| Param√®tre | Description | Options |
|-----------|-------------|---------|
| Type de recherche | Mode de recherche actif | **S√©mantique seule** / **Lexicale seule** / **Hybride** (d√©faut selon profilage) |

4. **CHAT** : le mode s√©lectionn√© dans les param√®tres g√©n√©raux est celui utilis√© par d√©faut. L'utilisateur peut toujours switcher temporairement via le s√©lecteur dans le chat.
5. **Chaque type de recherche reste param√©trable** dans son onglet avanc√© d√©di√© (√âtapes 5, 6, 7).

### Structure PARAM√àTRES √† cette √©tape

```
PARAM√àTRES
‚îú‚îÄ‚îÄ Param√®tres g√©n√©raux
‚îÇ   ‚îú‚îÄ‚îÄ Mode d'ingestion (Manuel / Automatique)
‚îÇ   ‚îî‚îÄ‚îÄ Type de recherche (S√©mantique / Lexicale / Hybride)
‚îî‚îÄ‚îÄ Param√®tres avanc√©s
    ‚îú‚îÄ‚îÄ INGESTION & PR√âPROCESSING
    ‚îú‚îÄ‚îÄ CHUNKING
    ‚îú‚îÄ‚îÄ EMBEDDING
    ‚îú‚îÄ‚îÄ BASE DE DONN√âES VECTORIELLE
    ‚îú‚îÄ‚îÄ RECHERCHE S√âMANTIQUE
    ‚îú‚îÄ‚îÄ RECHERCHE LEXICALE
    ‚îî‚îÄ‚îÄ RECHERCHE HYBRIDE
```

### Sortie attendue

> L'utilisateur choisit son mode de recherche pr√©f√©r√©. La recherche hybride combine les forces des deux approches avec un param√®tre `alpha` ajustable. Les r√©sultats fusionn√©s sont affich√©s dans le chat.

---

## √âtape 8 ‚Äî Reranking

### üéØ Objectif

Ajouter une couche de r√©ordonnancement intelligent des r√©sultats de recherche pour am√©liorer la pertinence finale des chunks s√©lectionn√©s.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > RERANKING`.
2. **Param√®tres** :
   - `enabled` : activ√©/d√©sactiv√© (d√©faut selon profilage)
   - `provider` : `cohere` | `local` (HuggingFace) | `none`
   - `model` : mod√®le de reranking (ex : `rerank-v3.5`, `BAAI/bge-reranker-v2-m3`)
   - `api_key` : cl√© API si provider cloud
   - `top_n` : nombre final de r√©sultats apr√®s reranking (ex : 5)
   - `candidates` : nombre de candidats envoy√©s au reranker (ex : 40)
   - `relevance_threshold` : score minimum apr√®s reranking
3. **Agent orchestrateur de recherche + reranking** :
   - L'agent combine automatiquement : recherche s√©mantique + recherche lexicale ‚Üí fusion ‚Üí reranking ‚Üí r√©sultats finaux.
   - Dans le **CHAT**, l'utilisateur soumet une requ√™te et voit les r√©sultats apr√®s reranking, avec les scores reclass√©s.
   - Possibilit√© d'afficher un mode debug montrant les scores avant/apr√®s reranking pour chaque chunk.

### Sortie attendue

> Les r√©sultats de recherche sont maintenant r√©ordonnanc√©s par un mod√®le de reranking. L'utilisateur voit les chunks les plus pertinents en premier. Le pipeline complet de retrieval est op√©rationnel : recherche hybride ‚Üí reranking ‚Üí r√©sultats.

---

## √âtape 9 ‚Äî LLM / G√©n√©ration

### üéØ Objectif

Ajouter la g√©n√©ration de r√©ponses en langage naturel par un LLM, en prenant comme contexte les chunks r√©cup√©r√©s aux √©tapes pr√©c√©dentes. C'est la brique qui transforme le moteur de recherche en v√©ritable assistant conversationnel.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > LLM / G√âN√âRATION`.
2. **Param√®tres** :
   - **Mod√®le principal** : `provider` (openai | anthropic | ollama | mistral), `model`, `api_key`
   - **Mod√®le secondaire / fallback** : configuration optionnelle d'un mod√®le de secours
   - **Param√®tres de g√©n√©ration** : `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`
   - **Timeouts** : `timeout`, `max_retries`
   - **Comportement** :
     - `cite_sources` : citer les sources dans la r√©ponse (bool√©en)
     - `citation_format` : format des citations (ex : `[Source: {nom}]`)
     - `admit_uncertainty` : admettre quand l'info n'est pas trouv√©e
     - `uncertainty_phrase` : phrase personnalisable pour l'incertitude
     - `response_language` : langue de r√©ponse (`auto` | `fr` | `en` | etc.)
   - **Prompt syst√®me** : zone de texte √©ditable pour le prompt syst√®me de g√©n√©ration
   - **Prompt hors-RAG** : prompt utilis√© pour les messages qui ne n√©cessitent pas de recherche (salutations, etc.)
3. **Ajout dans Param√®tres g√©n√©raux** :

| Param√®tre | Description | D√©faut |
|-----------|-------------|--------|
| Mod√®le LLM | Mod√®le de g√©n√©ration actif | Selon profilage |
| Temp√©rature | Cr√©ativit√© des r√©ponses (0.0 ‚Üí 1.0) | Selon profilage |
| Langue de r√©ponse | Langue pr√©f√©r√©e | Fran√ßais |
| Nombre de sources affich√©es | Sources cit√©es par r√©ponse | 3 |
| Prompt syst√®me | Instructions personnalisables | Prompt par d√©faut |

4. **Contexte final** (section dans les param√®tres avanc√©s) :
   - `max_chunks` : nombre max de chunks dans le contexte envoy√© au LLM
   - `max_tokens` : taille max du contexte en tokens
   - `deduplication` : d√©dupliquer les chunks trop similaires (`enabled`, `similarity_threshold`)

5. **CHAT** : l'utilisateur pose une question ‚Üí recherche hybride + reranking ‚Üí les chunks pertinents sont inject√©s dans le prompt ‚Üí le LLM g√©n√®re une r√©ponse en langage naturel avec citations. La r√©ponse affiche :
   - Le texte de la r√©ponse
   - Les sources utilis√©es (cliquables, avec extrait du chunk)
   - Optionnel : panneau debug (latence, intent, chunks, langue)

### Sortie attendue

> L'utilisateur a un chat RAG fonctionnel de bout en bout. Il pose une question, obtient une r√©ponse sourc√©e en langage naturel. Le pipeline complet fonctionne : parsing ‚Üí chunking ‚Üí embedding ‚Üí stockage ‚Üí recherche ‚Üí reranking ‚Üí g√©n√©ration.

---

## √âtape 10 ‚Äî Agents & Orchestration

### üéØ Objectif

Ajouter la couche d'intelligence qui analyse la requ√™te avant de d√©cider quoi en faire (RAG n√©cessaire ? reformulation ? hors-p√©rim√®tre ?) et orchestrer le flux complet de mani√®re intelligente.

### Fonctionnalit√©s

1. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > AGENTS`.
2. **Agent 1 ‚Äî Query Analyzer** :
   - Analyse l'intention de l'utilisateur : `question` | `greeting` | `chitchat` | `out_of_scope` | `clarification`
   - D√©cide si une recherche RAG est n√©cessaire
   - Reformule la requ√™te pour optimiser la recherche (`query_rewriting`)
   - **Param√®tres** : `always_retrieve` (bool√©en), `detect_intents` (liste), `query_rewriting.enabled`, `query_rewriting.num_rewrites`, prompt syst√®me personnalisable, LLM utilis√© (r√©f√©rence au mod√®le "fast")
3. **Agent 2 ‚Äî Response Generator** :
   - G√©n√®re la r√©ponse finale avec le contexte (d√©j√† configur√© √† l'√âtape 9, mais maintenant pilot√© par l'orchestrateur)
   - G√®re les cas sans RAG (salutations, hors-p√©rim√®tre) avec des prompts d√©di√©s
4. **Orchestrateur** :
   - Encha√Æne automatiquement : Query Analyzer ‚Üí (Retrieval si n√©cessaire) ‚Üí Response Generator
   - G√®re le streaming des r√©ponses token par token
   - Collecte les m√©triques de chaque composant (latence, succ√®s/√©chec)
5. **Conversation** :
   - `max_history_messages` : nombre de messages d'historique envoy√©s au LLM
   - `memory_strategy` : `sliding_window` | `summary`
   - `system_message_position` : `first` | `last`

### Sortie attendue

> Le chat est d√©sormais intelligent : il distingue les salutations des vraies questions, reformule les requ√™tes ambigu√´s, et orchestre le pipeline de fa√ßon optimale. Les r√©ponses hors-p√©rim√®tre sont g√©r√©es √©l√©gamment.

---

## √âtape 11 ‚Äî Monitoring & √âvaluation

### üéØ Objectif

Enrichir le tableau de bord avec des m√©triques de performance, des journaux de requ√™tes, et des outils de diagnostic pour que l'utilisateur puisse suivre et am√©liorer la qualit√© de son RAG.

### Fonctionnalit√©s

1. **Tableau de bord enrichi** :
   - **√âtat des services** : indicateurs temps r√©el (üü¢ OK / üü° Chargement / üî¥ Erreur / ‚ö™ D√©sactiv√©) pour chaque composant (Embedding, LLM, Reranker, Vector DB)
   - **Statistiques d'ingestion** : total docs, total chunks, derni√®re mise √† jour, couverture vectorielle
   - **M√©triques de requ√™tes (24h)** : nombre de requ√™tes, taux de r√©ussite, latence moyenne/p95, co√ªt estim√©
   - **Graphique** : volume de requ√™tes dans le temps
   - **Requ√™tes r√©centes** : liste des derni√®res questions avec latence et intent d√©tect√©
2. **Journaux de requ√™tes** (onglet d√©di√© ou sous-section) :
   - Historique complet des requ√™tes avec filtres (date, intent, statut)
   - Pour chaque requ√™te : question, intent, chunks r√©cup√©r√©s, r√©ponse, latence, feedback utilisateur
3. **Feedback utilisateur** :
   - Boutons üëç/üëé sur chaque r√©ponse du chat
   - Collecte pour am√©lioration continue
4. **Nouvel onglet** : `PARAM√àTRES > Param√®tres avanc√©s > MONITORING`.
5. **Param√®tres** :
   - `log_queries` : journaliser les requ√™tes (bool√©en)
   - `log_retrieval_results` : journaliser les r√©sultats de recherche
   - `log_llm_outputs` : journaliser les r√©ponses LLM
   - `feedback_collection` : activer la collecte de feedback
   - `latency_p50`, `latency_p95`, `latency_p99` : seuils d'alerte de latence

### Sortie attendue

> Le tableau de bord offre une vue compl√®te de la sant√© du syst√®me : services, ingestion, requ√™tes, performances. L'utilisateur peut diagnostiquer les probl√®mes et suivre l'√©volution de la qualit√©.

---

## √âtape 12 ‚Äî S√©curit√©, UX & Finalisation

### üéØ Objectif

Consolider l'application avec les fonctionnalit√©s de s√©curit√©, les finitions UX, et les outils d'import/export pour une utilisation en production.

### Fonctionnalit√©s

#### 12.1 ‚Äî S√©curit√© & confidentialit√©

- Stockage chiffr√© des cl√©s API (AES-256)
- D√©tection optionnelle de donn√©es personnelles (PII) dans les documents
- Anonymisation optionnelle des PII avant indexation
- Politique de r√©tention des logs configurable

#### 12.2 ‚Äî Export & import

- **Export de configuration** : exporter l'int√©gralit√© de la configuration en fichier `.yaml` ou `.ragkit-config`
- **Import de configuration** : r√©importer une configuration export√©e
- **Export de conversations** : exporter les sessions de chat en Markdown ou PDF

#### 12.3 ‚Äî UX & finitions

- **Mode partiel** : le chat devient disponible d√®s que les N premiers documents sont ing√©r√©s, m√™me si l'ingestion continue en arri√®re-plan
- **Question de test automatique** : apr√®s la premi√®re ingestion, RAGKIT propose une question-test g√©n√©r√©e √† partir des documents pour valider le bon fonctionnement
- **Panneau de debug dans le chat** (activable) : affichage de l'intent, des chunks, de la latence, du streaming, de la langue d√©tect√©e
- **Niveaux d'expertise** : l'utilisateur peut choisir son niveau (Simple / Interm√©diaire / Expert) pour voir plus ou moins de param√®tres dans l'interface

#### 12.4 ‚Äî Param√®tres g√©n√©raux complets

R√©capitulatif de tous les param√®tres g√©n√©raux accumul√©s au fil des √©tapes :

| Param√®tre | Description | D√©faut |
|-----------|-------------|--------|
| Mode d'ingestion | Manuel / Automatique | Manuel |
| Type de recherche | S√©mantique / Lexicale / Hybride | Selon profil |
| Mod√®le LLM | Mod√®le de g√©n√©ration | Selon profil |
| Temp√©rature | Cr√©ativit√© (0.0‚Äì1.0) | Selon profil |
| Langue de r√©ponse | Langue pr√©f√©r√©e | Fran√ßais |
| Nb sources affich√©es | Citations par r√©ponse | 3 |
| Prompt syst√®me | Instructions LLM | D√©faut |
| Mode watch | Surveiller le r√©pertoire | Selon profil |
| Th√®me | Clair / Sombre / Syst√®me | Syst√®me |
| Niveau d'expertise | Simple / Interm√©diaire / Expert | Simple |
| Export config | Exporter / Importer | ‚Äî |

### Structure PARAM√àTRES finale

```
PARAM√àTRES
‚îú‚îÄ‚îÄ Param√®tres g√©n√©raux
‚îÇ   ‚îú‚îÄ‚îÄ Mode d'ingestion
‚îÇ   ‚îú‚îÄ‚îÄ Type de recherche
‚îÇ   ‚îú‚îÄ‚îÄ Mod√®le LLM
‚îÇ   ‚îú‚îÄ‚îÄ Temp√©rature
‚îÇ   ‚îú‚îÄ‚îÄ Langue de r√©ponse
‚îÇ   ‚îú‚îÄ‚îÄ Nombre de sources
‚îÇ   ‚îú‚îÄ‚îÄ Prompt syst√®me
‚îÇ   ‚îú‚îÄ‚îÄ Mode watch
‚îÇ   ‚îú‚îÄ‚îÄ Th√®me
‚îÇ   ‚îú‚îÄ‚îÄ Niveau d'expertise
‚îÇ   ‚îî‚îÄ‚îÄ Export / Import config
‚îî‚îÄ‚îÄ Param√®tres avanc√©s
    ‚îú‚îÄ‚îÄ INGESTION & PR√âPROCESSING
    ‚îú‚îÄ‚îÄ CHUNKING
    ‚îú‚îÄ‚îÄ EMBEDDING
    ‚îú‚îÄ‚îÄ BASE DE DONN√âES VECTORIELLE
    ‚îú‚îÄ‚îÄ RECHERCHE S√âMANTIQUE
    ‚îú‚îÄ‚îÄ RECHERCHE LEXICALE
    ‚îú‚îÄ‚îÄ RECHERCHE HYBRIDE
    ‚îú‚îÄ‚îÄ RERANKING
    ‚îú‚îÄ‚îÄ LLM / G√âN√âRATION
    ‚îú‚îÄ‚îÄ AGENTS
    ‚îî‚îÄ‚îÄ MONITORING
```

### Sortie attendue

> L'application est compl√®te, s√©curis√©e, et pr√™te pour une utilisation en production. L'utilisateur dispose d'un RAG local complet avec wizard de configuration, chat intelligent avec sources, tableau de bord de monitoring, et param√©trage fin de chaque composant du pipeline.

---

## R√©capitulatif des releases

| √âtape | Release | Ce qui fonctionne |
|-------|---------|-------------------|
| 0 | v0.1 | `.exe` installable, coquille vide avec navigation |
| 1 | v0.2 | Wizard complet, analyse de documents, m√©tadonn√©es |
| 2 | v0.3 | Chunking param√©trable avec pr√©visualisation |
| 3 | v0.4 | Embedding configurable avec test de connexion |
| 4 | v0.5 | **Ingestion de bout en bout**, monitoring, versioning |
| 5 | v0.6 | Recherche s√©mantique dans le chat |
| 6 | v0.7 | Recherche lexicale (BM25) dans le chat |
| 7 | v0.8 | Recherche hybride configurable |
| 8 | v0.9 | Reranking, r√©sultats optimis√©s |
| 9 | v0.10 | **Chat RAG complet** avec r√©ponses LLM sourc√©es |
| 10 | v0.11 | Agents intelligents, orchestration, reformulation |
| 11 | v0.12 | Tableau de bord enrichi, m√©triques, logs |
| 12 | v1.0 | **Release finale** : s√©curit√©, export, polish UX |
