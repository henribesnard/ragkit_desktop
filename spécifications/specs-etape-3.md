# ğŸ§° RAGKIT Desktop â€” SpÃ©cifications Ã‰tape 3 : Embedding

> **Ã‰tape** : 3 â€” Embedding  
> **Tag cible** : `v0.4.0`  
> **Date** : 16 fÃ©vrier 2026  
> **DÃ©pÃ´t** : https://github.com/henribesnard/ragkit_desktop.git  
> **PrÃ©requis** : Ã‰tape 2 (Chunking) implÃ©mentÃ©e et validÃ©e

---

## 1. Objectif

Ajouter la **vectorisation des chunks** via des modÃ¨les d'embedding configurables, qu'ils soient hÃ©bergÃ©s dans le cloud (API) ou exÃ©cutÃ©s localement. L'embedding est la brique qui transforme les chunks textuels en vecteurs numÃ©riques exploitables par la recherche sÃ©mantique.

Cette Ã©tape livre :
- Une section `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > EMBEDDING` complÃ¨te et fonctionnelle.
- Le **support de 6 providers d'embedding** : OpenAI, Ollama, HuggingFace (local via ONNX ou sentence-transformers), Cohere, VoyageAI, Mistral.
- Un **gestionnaire de clÃ©s API** sÃ©curisÃ© (premier composant de gestion des secrets dans RAGKIT).
- La **dÃ©tection automatique de l'environnement** (GPU, Ollama, modÃ¨les locaux disponibles).
- Un **bouton de test de connexion** pour valider la configuration du provider.
- Un **panneau de test d'embedding** pour visualiser la vectorisation d'un texte-Ã©chantillon et la similaritÃ© entre deux textes.
- Le **pipeline interne parsing â†’ chunking â†’ embedding** fonctionnel de bout en bout.
- Le remplacement du modÃ¨le lÃ©ger de l'Ã‰tape 2 (chunking sÃ©mantique) par le modÃ¨le configurÃ© par l'utilisateur.

**Le stockage vectoriel et l'indexation ne sont pas encore implÃ©mentÃ©s.** L'embedding s'exÃ©cute pour les tests et la validation, mais les vecteurs ne sont pas encore persistÃ©s dans une base vectorielle.

---

## 2. SpÃ©cifications fonctionnelles

### 2.1 Section PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > EMBEDDING

#### Structure de l'onglet PARAMÃˆTRES Ã  cette Ã©tape

```
PARAMÃˆTRES
â”œâ”€â”€ ParamÃ¨tres gÃ©nÃ©raux              â† (vide pour l'instant)
â””â”€â”€ ParamÃ¨tres avancÃ©s
    â”œâ”€â”€ INGESTION & PRÃ‰PROCESSING    â† Ã‰tape 1
    â”œâ”€â”€ CHUNKING                     â† Ã‰tape 2
    â””â”€â”€ EMBEDDING                    â† NOUVEAU
```

#### Layout de la section EMBEDDING

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EMBEDDING                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Environnement dÃ©tectÃ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ–¥ï¸ GPU : âšª Non dÃ©tectÃ©                                   â”‚ â”‚
â”‚  â”‚  ğŸ¦™ Ollama : ğŸŸ¢ InstallÃ© (v0.5.1) Â· 3 modÃ¨les disponiblesâ”‚ â”‚
â”‚  â”‚  ğŸ“¦ ModÃ¨les locaux : all-MiniLM-L6-v2 (cache)            â”‚ â”‚
â”‚  â”‚  [â†» RafraÃ®chir]                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ ModÃ¨le de documents â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  Provider :            [â–¾ openai             ]            â”‚ â”‚
â”‚  â”‚  ModÃ¨le :              [â–¾ text-embedding-3-small ]        â”‚ â”‚
â”‚  â”‚  ClÃ© API :             [â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢] [ğŸ‘] [âœ]     â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â„¹ï¸ OpenAI text-embedding-3-small : 1536 dimensions,       â”‚ â”‚
â”‚  â”‚  max 8191 tokens, ~$0.02/1M tokens. Bon rapport            â”‚ â”‚
â”‚  â”‚  qualitÃ©/prix pour la plupart des cas d'usage.             â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  [ğŸ”Œ Tester la connexion]     ğŸŸ¢ Connexion rÃ©ussie        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ ModÃ¨le de requÃªtes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  â˜‘ Identique au modÃ¨le de documents                       â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  (si dÃ©cochÃ© : mÃªmes champs que ci-dessus)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ ParamÃ¨tres de vectorisation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Dimensions :          [â–¾ 1536 (dÃ©faut)      ]  â„¹ï¸        â”‚ â”‚
â”‚  â”‚  Batch size :          [===â—†=========] 100                â”‚ â”‚
â”‚  â”‚  â˜‘ Normalisation L2                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  â˜‘ Activer le cache d'embeddings                          â”‚ â”‚
â”‚  â”‚  Backend :             [â–¾ disk               ]            â”‚ â”‚
â”‚  â”‚  ğŸ“Š Cache : 0 entrÃ©es Â· 0 Mo                              â”‚ â”‚
â”‚  â”‚  [ğŸ—‘ Vider le cache]                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â–¸ ParamÃ¨tres avancÃ©s                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Timeout (secondes) :  [===â—†=========] 30                 â”‚ â”‚
â”‚  â”‚  Max retries :         [=â—†===========] 3                  â”‚ â”‚
â”‚  â”‚  Rate limit (req/min): [========â—†====] 3000               â”‚ â”‚
â”‚  â”‚  Truncation :          [â–¾ end                ]            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€ Test d'embedding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Texte A : [Le contrat de service dÃ©finit les...     ]    â”‚ â”‚
â”‚  â”‚  Texte B : [Les obligations du prestataire sont...   ]    â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  [â–¶ Tester l'embedding]                                   â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  RÃ©sultat :                                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚  Texte A : 1536 dimensions Â· 12 tokens Â· 23 ms    â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  Texte B : 1536 dimensions Â· 10 tokens Â· 21 ms    â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  SimilaritÃ© cosinus : 0.847 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ (Ã©levÃ©e)    â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  [â†» RÃ©initialiser au profil]                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Panneau Environnement dÃ©tectÃ©

Au chargement de la section EMBEDDING, le backend exÃ©cute une dÃ©tection de l'environnement local. Le panneau affiche :

| Ã‰lÃ©ment | DÃ©tection | Affichage |
|---------|-----------|-----------|
| **GPU** | VÃ©rification CUDA (via `torch.cuda.is_available()` ou `onnxruntime.get_available_providers()`) et MPS (macOS Apple Silicon) | ğŸŸ¢ `NVIDIA RTX 3060 (CUDA 12.1)` / ğŸŸ¢ `Apple MPS` / âšª `Non dÃ©tectÃ©` |
| **Ollama** | VÃ©rification binaire dans le PATH + appel `ollama list` | ğŸŸ¢ `InstallÃ© (vX.X) Â· N modÃ¨les` / ğŸ”´ `Non installÃ©` |
| **ModÃ¨les locaux** | Cache de modÃ¨les sentence-transformers / ONNX dans `~/.ragkit/models/` | Liste des modÃ¨les en cache |

**Comportements** :
- Le bouton "RafraÃ®chir" relance la dÃ©tection.
- Si Ollama n'est pas installÃ©, un lien vers les instructions d'installation est affichÃ©.
- Si aucun GPU n'est dÃ©tectÃ©, un message informatif est affichÃ© : "Les modÃ¨les locaux fonctionneront sur CPU (plus lent). Un GPU accÃ©lÃ¨re considÃ©rablement l'embedding."
- La dÃ©tection ne bloque pas le chargement de la page ; elle s'exÃ©cute en arriÃ¨re-plan avec un spinner.

### 2.3 SÃ©lection du provider et du modÃ¨le

#### Providers supportÃ©s et modÃ¨les associÃ©s

| Provider | ID config | ModÃ¨les proposÃ©s | ClÃ© API requise | Local/Cloud |
|----------|-----------|-------------------|:---:|:---:|
| **OpenAI** | `openai` | `text-embedding-3-small` (1536d), `text-embedding-3-large` (3072d), `text-embedding-ada-002` (1536d) | âœ… | Cloud |
| **Ollama** | `ollama` | (dynamique : liste depuis `ollama list`, filtrÃ©e aux modÃ¨les d'embedding) | âŒ | Local |
| **HuggingFace / Local** | `huggingface` | `all-MiniLM-L6-v2` (384d), `multilingual-e5-large` (1024d), `bge-large-en-v1.5` (1024d), `nomic-embed-text-v1.5` (768d), champ libre pour modÃ¨le custom | âŒ | Local |
| **Cohere** | `cohere` | `embed-multilingual-v3.0` (1024d), `embed-english-v3.0` (1024d), `embed-multilingual-light-v3.0` (384d) | âœ… | Cloud |
| **VoyageAI** | `voyageai` | `voyage-3` (1024d), `voyage-3-lite` (512d), `voyage-multilingual-2` (1024d) | âœ… | Cloud |
| **Mistral** | `mistral` | `mistral-embed` (1024d) | âœ… | Cloud |

**Comportements** :
- Quand l'utilisateur change de provider, la liste des modÃ¨les se met Ã  jour.
- Pour Ollama : la liste est dynamique (appel `ollama list`). Si Ollama n'est pas installÃ©, le provider est grisÃ© avec un message "Ollama non dÃ©tectÃ©".
- Pour HuggingFace : une liste prÃ©-remplie des modÃ¨les les plus courants est proposÃ©e, avec un champ "ModÃ¨le personnalisÃ©" permettant de saisir un identifiant HuggingFace libre (ex : `BAAI/bge-m3`).
- Chaque modÃ¨le affiche une fiche descriptive sous le sÃ©lecteur (dimensions, max tokens, coÃ»t estimÃ© pour les providers cloud, langue supportÃ©e).

#### Fiches des modÃ¨les (exemples)

| ModÃ¨le | Dimensions | Max tokens | CoÃ»t estimÃ© | Langues | Notes |
|--------|:---:|:---:|---|---|---|
| `text-embedding-3-small` | 1536 | 8191 | ~$0.02/1M tokens | Multilingue | Bon rapport qualitÃ©/prix |
| `text-embedding-3-large` | 3072 | 8191 | ~$0.13/1M tokens | Multilingue | Plus prÃ©cis, plus cher |
| `embed-multilingual-v3.0` | 1024 | 512 | ~$0.10/1M tokens | 100+ langues | Excellent pour le multilingue |
| `all-MiniLM-L6-v2` | 384 | 256 | Gratuit (local) | Anglais (correct FR) | LÃ©ger, rapide, ~80 Mo |
| `multilingual-e5-large` | 1024 | 512 | Gratuit (local) | Multilingue | ~2.2 Go, nÃ©cessite GPU recommandÃ© |
| `mistral-embed` | 1024 | 8192 | ~$0.10/1M tokens | Multilingue | Bon pour le franÃ§ais |

### 2.4 Gestion des clÃ©s API

L'Ã‰tape 3 introduit le **premier composant de gestion sÃ©curisÃ©e des secrets** dans RAGKIT. Ce composant sera rÃ©utilisÃ© aux Ã©tapes suivantes (reranking Cohere, LLM, etc.).

#### Architecture de sÃ©curitÃ© des clÃ©s

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Gestion des clÃ©s API                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  1. Saisie : champ masquÃ© (â€¢â€¢â€¢) avec toggle ğŸ‘     â”‚
â”‚                                                     â”‚
â”‚  2. Stockage primaire : keyring systÃ¨me natif       â”‚
â”‚     â””â”€ Windows : Windows Credential Manager         â”‚
â”‚     â””â”€ macOS   : Keychain                           â”‚
â”‚     â””â”€ Linux   : Secret Service (GNOME Keyring)     â”‚
â”‚                                                     â”‚
â”‚  3. Fallback : fichier ~/.ragkit/credentials.enc    â”‚
â”‚     â””â”€ Chiffrement AES-256-GCM                      â”‚
â”‚     â””â”€ ClÃ© dÃ©rivÃ©e de la machine (PBKDF2)           â”‚
â”‚                                                     â”‚
â”‚  4. En mÃ©moire : jamais persistÃ©e en clair          â”‚
â”‚     â””â”€ DÃ©chiffrÃ©e Ã  la volÃ©e pour chaque appel API  â”‚
â”‚     â””â”€ Jamais loggÃ©e, jamais dans settings.json     â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**RÃ¨gles de sÃ©curitÃ© strictes** :
- Les clÃ©s API ne sont **jamais** stockÃ©es dans `settings.json`.
- Les clÃ©s API ne sont **jamais** loggÃ©es (ni en clair, ni en hash).
- Le champ `api_key` dans `settings.json` contient uniquement un **indicateur** : `"api_key_set": true/false`.
- Les clÃ©s sont stockÃ©es dans le trousseau systÃ¨me natif (`keyring`) avec le service `ragkit` et un nom de clÃ© structurÃ© (ex : `ragkit.embedding.openai.api_key`).
- Si `keyring` n'est pas disponible (environnement headless), fallback sur un fichier chiffrÃ© `~/.ragkit/credentials.enc` (AES-256-GCM, clÃ© dÃ©rivÃ©e via PBKDF2 Ã  partir d'un identifiant machine).

**Interface utilisateur** :
- Le champ de clÃ© API est masquÃ© par dÃ©faut (caractÃ¨res `â€¢`).
- Bouton ğŸ‘ pour afficher/masquer temporairement la clÃ©.
- Bouton âœ pour modifier la clÃ© (ouvre un champ de saisie).
- Indicateur visuel : ğŸŸ¢ "ClÃ© configurÃ©e" / ğŸ”´ "ClÃ© manquante".
- Bouton ğŸ—‘ pour supprimer la clÃ© stockÃ©e (avec confirmation).

### 2.5 ModÃ¨le de requÃªtes (Query Model)

Par dÃ©faut, la case "Identique au modÃ¨le de documents" est cochÃ©e. Dans ce cas, le mÃªme modÃ¨le/provider est utilisÃ© pour les embeddings de documents et de requÃªtes.

Si l'utilisateur dÃ©coche, un second bloc de configuration identique apparaÃ®t pour le modÃ¨le de requÃªtes. Cas d'usage : certains modÃ¨les asymÃ©triques ont des modÃ¨les distincts pour documents et queries (ex : `intfloat/e5-*` avec prÃ©fixes `passage:` et `query:`).

**Note** : le provider du modÃ¨le de requÃªtes peut Ãªtre diffÃ©rent de celui du modÃ¨le de documents (ex : OpenAI pour les documents, Ollama local pour les requÃªtes), mais les **dimensions doivent Ãªtre identiques**. Si les dimensions diffÃ¨rent, un avertissement s'affiche : "âš ï¸ Les dimensions du modÃ¨le de requÃªtes (384) ne correspondent pas Ã  celles du modÃ¨le de documents (1536). La recherche ne fonctionnera pas correctement."

### 2.6 Test de connexion

Le bouton "ğŸ”Œ Tester la connexion" envoie un texte de test au provider configurÃ© et vÃ©rifie :

1. **AccessibilitÃ©** : le provider est joignable (rÃ©seau, URL).
2. **Authentification** : la clÃ© API est valide (pour les providers cloud).
3. **ModÃ¨le** : le modÃ¨le demandÃ© est disponible.
4. **RÃ©sultat** : un vecteur est retournÃ© avec les bonnes dimensions.

| Statut | Affichage |
|--------|-----------|
| SuccÃ¨s | ğŸŸ¢ "Connexion rÃ©ussie Â· 1536 dimensions Â· 145 ms" |
| Erreur auth | ğŸ”´ "ClÃ© API invalide ou expirÃ©e" |
| Erreur rÃ©seau | ğŸ”´ "Provider injoignable â€” vÃ©rifiez votre connexion" |
| ModÃ¨le inconnu | ğŸ”´ "ModÃ¨le 'xxx' non trouvÃ© chez le provider" |
| Timeout | ğŸŸ¡ "Timeout aprÃ¨s 30s â€” essayez avec un modÃ¨le plus lÃ©ger" |

### 2.7 Panneau de test d'embedding

Ce panneau permet Ã  l'utilisateur de tester interactivement l'embedding et de comprendre la similaritÃ© sÃ©mantique.

**Fonctionnement** :
1. Deux champs de texte libre (Texte A, Texte B) prÃ©-remplis avec des exemples pertinents au profil actif.
2. Bouton "Tester l'embedding" : envoie les deux textes au provider, rÃ©cupÃ¨re les vecteurs, calcule la similaritÃ© cosinus.
3. **Affichage des rÃ©sultats** :
   - Dimensions du vecteur retournÃ©
   - Nombre de tokens de chaque texte
   - Latence de chaque appel (ms)
   - **SimilaritÃ© cosinus** entre les deux vecteurs, avec barre visuelle et qualificatif :
     - 0.0 â€” 0.3 : "Faible" (rouge)
     - 0.3 â€” 0.6 : "ModÃ©rÃ©e" (orange)
     - 0.6 â€” 0.8 : "Ã‰levÃ©e" (vert clair)
     - 0.8 â€” 1.0 : "TrÃ¨s Ã©levÃ©e" (vert)

**Valeurs prÃ©-remplies selon le profil** :

| Profil | Texte A (exemple) | Texte B (exemple) |
|--------|-------------------|-------------------|
| `technical_documentation` | "Comment configurer l'authentification OAuth2 dans l'API REST ?" | "Configuration de l'authentification et des tokens d'accÃ¨s" |
| `faq_support` | "Je n'arrive pas Ã  me connecter Ã  mon compte" | "ProblÃ¨me de connexion et rÃ©initialisation du mot de passe" |
| `legal_compliance` | "Les obligations du prestataire sont dÃ©finies Ã  l'article 5" | "Article 5 â€” Engagements et responsabilitÃ©s du fournisseur" |
| `reports_analysis` | "Le chiffre d'affaires a progressÃ© de 12% au T3 2024" | "Croissance des revenus au troisiÃ¨me trimestre" |
| `general` | "Les effets du changement climatique sur l'agriculture" | "Impact du rÃ©chauffement global sur les cultures" |

### 2.8 Dimensions configurables

Certains modÃ¨les permettent de choisir les dimensions du vecteur (ex : OpenAI `text-embedding-3-small` peut produire 256, 512, 1024 ou 1536 dimensions via le paramÃ¨tre `dimensions`).

**Comportements** :
- Si le modÃ¨le supporte des dimensions variables, un sÃ©lecteur dropdown apparaÃ®t avec les options du modÃ¨le et la valeur par dÃ©faut sÃ©lectionnÃ©e.
- Si le modÃ¨le a des dimensions fixes, le champ affiche la valeur en lecture seule avec un tooltip "Ce modÃ¨le ne supporte qu'une seule dimension."
- Une note informative est affichÃ©e : "Moins de dimensions = plus rapide et moins de stockage, mais potentiellement moins prÃ©cis."

### 2.9 Cache d'embeddings

Le cache Ã©vite de recalculer des embeddings pour des textes dÃ©jÃ  vectorisÃ©s. Il est particuliÃ¨rement utile pendant la phase d'itÃ©ration (modification de paramÃ¨tres de chunking â†’ re-embedding).

| Backend | Stockage | Persistance | Performance |
|---------|----------|:-----------:|-------------|
| `memory` | Dictionnaire en mÃ©moire | Non (perdu au redÃ©marrage) | TrÃ¨s rapide |
| `disk` | Fichier SQLite dans `~/.ragkit/cache/embeddings.db` | Oui | Rapide |

**Comportements** :
- Le cache utilise un hash SHA-256 du texte + identifiant modÃ¨le comme clÃ©.
- Le compteur affiche le nombre d'entrÃ©es et la taille du cache.
- Le bouton "Vider le cache" supprime toutes les entrÃ©es (avec confirmation).
- Si l'utilisateur change de modÃ¨le d'embedding, le cache est automatiquement invalidÃ© (car les vecteurs ne sont plus compatibles). Un avertissement s'affiche : "âš ï¸ Le changement de modÃ¨le invalidera le cache d'embeddings existant (N entrÃ©es)."

### 2.10 IntÃ©gration avec le chunking sÃ©mantique (Ã‰tape 2)

Ã€ l'Ã‰tape 2, le chunking sÃ©mantique utilisait un modÃ¨le lÃ©ger embarquÃ© (`all-MiniLM-L6-v2`). Ã€ partir de l'Ã‰tape 3, si l'utilisateur a configurÃ© un modÃ¨le d'embedding :
- Le chunking sÃ©mantique utilise **le modÃ¨le d'embedding configurÃ©** au lieu du modÃ¨le embarquÃ©.
- Si le modÃ¨le configurÃ© est un provider cloud (OpenAI, Cohereâ€¦), un avertissement est affichÃ© dans les paramÃ¨tres de chunking : "âš ï¸ Le chunking sÃ©mantique avec un provider cloud gÃ©nÃ¨re des coÃ»ts API. Pour la prÃ©visualisation, le modÃ¨le lÃ©ger embarquÃ© reste utilisÃ©."
- La **prÃ©visualisation** du chunking continue d'utiliser le modÃ¨le lÃ©ger (pour ne pas consommer de crÃ©dits API Ã  chaque clic sur "PrÃ©visualiser").

---

## 3. Catalogue complet des paramÃ¨tres EMBEDDING

### 3.1 ParamÃ¨tres du modÃ¨le de documents

| ParamÃ¨tre | ClÃ© config | Type | Options | DÃ©faut | Description |
|-----------|------------|------|---------|--------|-------------|
| Provider | `embedding.provider` | enum | `openai` \| `ollama` \| `huggingface` \| `cohere` \| `voyageai` \| `mistral` | Selon profil | Fournisseur du modÃ¨le d'embedding |
| ModÃ¨le | `embedding.model` | string | DÃ©pend du provider | Selon profil | Identifiant du modÃ¨le |
| ClÃ© API configurÃ©e | `embedding.api_key_set` | bool | â€” | `false` | Indicateur uniquement (la clÃ© est dans keyring) |

### 3.2 ParamÃ¨tres du modÃ¨le de requÃªtes

| ParamÃ¨tre | ClÃ© config | Type | DÃ©faut | Description |
|-----------|------------|------|--------|-------------|
| Identique au document | `embedding.query_model.same_as_document` | bool | `true` | Utiliser le mÃªme modÃ¨le pour les documents et les requÃªtes |
| Provider (requÃªtes) | `embedding.query_model.provider` | enum | â€” | Provider spÃ©cifique pour les requÃªtes (si diffÃ©rent) |
| ModÃ¨le (requÃªtes) | `embedding.query_model.model` | string | â€” | ModÃ¨le spÃ©cifique pour les requÃªtes (si diffÃ©rent) |

### 3.3 ParamÃ¨tres de vectorisation

| ParamÃ¨tre | ClÃ© config | Type | Min | Max | DÃ©faut | Description |
|-----------|------------|------|-----|-----|--------|-------------|
| Dimensions | `embedding.dimensions` | int \| null | 64 | 4096 | `null` (auto) | Nombre de dimensions du vecteur. `null` = utiliser la dimension par dÃ©faut du modÃ¨le. |
| Batch size | `embedding.batch_size` | int | 1 | 2048 | Selon profil | Nombre de textes envoyÃ©s par requÃªte d'embedding. Plus haut = plus rapide mais plus de mÃ©moire. |
| Normalisation L2 | `embedding.normalize` | bool | â€” | â€” | `true` | Normaliser les vecteurs (norme L2 = 1). NÃ©cessaire pour la similaritÃ© cosinus. |

### 3.4 ParamÃ¨tres de cache

| ParamÃ¨tre | ClÃ© config | Type | Options | DÃ©faut | Description |
|-----------|------------|------|---------|--------|-------------|
| Cache activÃ© | `embedding.cache_enabled` | bool | â€” | `true` | Mettre en cache les embeddings pour Ã©viter les recalculs |
| Backend de cache | `embedding.cache_backend` | enum | `memory` \| `disk` | `disk` | `memory` = en mÃ©moire (perdu au redÃ©marrage). `disk` = SQLite persistant. |

### 3.5 ParamÃ¨tres avancÃ©s

| ParamÃ¨tre | ClÃ© config | Type | Min | Max | DÃ©faut | Description |
|-----------|------------|------|-----|-----|--------|-------------|
| Timeout | `embedding.timeout` | int (s) | 5 | 120 | 30 | Timeout par requÃªte d'embedding |
| Max retries | `embedding.max_retries` | int | 0 | 10 | 3 | Nombre de tentatives en cas d'Ã©chec rÃ©seau/API |
| Rate limit | `embedding.rate_limit_rpm` | int | 0 | 10000 | 3000 | Limite de requÃªtes par minute (0 = illimitÃ©). Respect des quotas API du provider. |
| Truncation | `embedding.truncation` | enum | `start` \| `end` \| `middle` | `end` | StratÃ©gie si le texte dÃ©passe la limite de tokens du modÃ¨le. `end` = tronque la fin. |

### 3.6 RÃ©sumÃ© des impacts

| ParamÃ¨tre | Impact principal | Impact secondaire |
|-----------|-----------------|-------------------|
| `provider` + `model` | **FONDAMENTAL** â€” QualitÃ© de la comprÃ©hension sÃ©mantique | CoÃ»t, latence, nÃ©cessitÃ© d'une clÃ© API |
| `dimensions` | Compromis prÃ©cision / stockage / performance | Affecte la taille de la BDD vectorielle |
| `batch_size` | Vitesse d'ingestion | Utilisation mÃ©moire, risque de timeout |
| `normalize` | CohÃ©rence des scores de similaritÃ© | Quasi obligatoire pour cosine similarity |
| `cache_enabled` | Ã‰conomies de coÃ»t et de temps lors des rÃ©-embeddings | Espace disque |
| `timeout` | TolÃ©rance aux latences rÃ©seau | Risque de faux nÃ©gatifs si trop court |
| `rate_limit_rpm` | Respect des quotas API | Peut ralentir l'ingestion |
| `truncation` | Gestion des chunks dÃ©passant la limite du modÃ¨le | Perte d'information en fin/dÃ©but de chunk |

---

## 4. Valeurs par dÃ©faut par profil

Les valeurs par dÃ©faut sont dÃ©jÃ  calculÃ©es et stockÃ©es dans `settings.json` par le wizard de l'Ã‰tape 1 (section `embedding`). Cette Ã©tape **active et utilise** ces valeurs.

### 4.1 Matrice profil â†’ paramÃ¨tres d'embedding

| ParamÃ¨tre | `technical_documentation` | `faq_support` | `legal_compliance` | `reports_analysis` | `general` |
|-----------|:---:|:---:|:---:|:---:|:---:|
| `provider` | `openai` | `openai` | `openai` | `openai` | `openai` |
| `model` | `text-embedding-3-small` | `text-embedding-3-small` | `text-embedding-3-small` | `text-embedding-3-small` | `text-embedding-3-small` |
| `batch_size` | 100 | 100 | 50 | 100 | 100 |
| `cache_enabled` | `true` | `true` | `true` | `true` | `true` |
| `normalize` | `true` | `true` | `true` | `true` | `true` |
| `dimensions` | `null` (1536) | `null` (1536) | `null` (1536) | `null` (1536) | `null` (1536) |
| `cache_backend` | `disk` | `disk` | `disk` | `disk` | `disk` |
| `timeout` | 30 | 30 | 30 | 30 | 30 |
| `max_retries` | 3 | 3 | 3 | 3 | 3 |
| `rate_limit_rpm` | 3000 | 3000 | 3000 | 3000 | 3000 |
| `truncation` | `end` | `end` | `end` | `end` | `end` |
| `query_model.same_as_document` | `true` | `true` | `true` | `true` | `true` |

### 4.2 Justification des choix

Tous les profils utilisent OpenAI `text-embedding-3-small` par dÃ©faut, car c'est le modÃ¨le qui offre le meilleur compromis qualitÃ©/coÃ»t/simplicitÃ© de configuration pour un premier usage. Les modÃ¨les locaux (Ollama, HuggingFace) sont proposÃ©s en alternative mais nÃ©cessitent une installation supplÃ©mentaire.

Le profil `legal_compliance` utilise un `batch_size` de 50 (au lieu de 100) pour Ãªtre plus conservateur avec les gros chunks juridiques (1024+ tokens) qui approchent de la limite du modÃ¨le.

### 4.3 Impact des modificateurs de calibrage sur l'embedding

Aucune question de calibrage de l'Ã‰tape 1 n'impacte directement les paramÃ¨tres d'embedding. Les valeurs sont uniformes entre profils (seul `batch_size` varie).

---

## 5. SpÃ©cifications techniques

### 5.1 SchÃ©ma Pydantic (backend)

```python
# ragkit/config/embedding_schema.py
"""Pydantic schemas for embedding configuration."""

from __future__ import annotations

from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field, model_validator


class EmbeddingProvider(str, Enum):
    OPENAI = "openai"
    OLLAMA = "ollama"
    HUGGINGFACE = "huggingface"
    COHERE = "cohere"
    VOYAGEAI = "voyageai"
    MISTRAL = "mistral"


class TruncationStrategy(str, Enum):
    START = "start"
    END = "end"
    MIDDLE = "middle"


class CacheBackend(str, Enum):
    MEMORY = "memory"
    DISK = "disk"


class QueryModelConfig(BaseModel):
    """Configuration for the query embedding model."""
    same_as_document: bool = True
    provider: EmbeddingProvider | None = None
    model: str | None = None
    api_key_set: bool = False

    @model_validator(mode="after")
    def validate_query_model(self) -> "QueryModelConfig":
        if not self.same_as_document:
            if self.provider is None or self.model is None:
                raise ValueError(
                    "provider and model are required when "
                    "same_as_document is False")
        return self


class EmbeddingConfig(BaseModel):
    """Complete embedding configuration."""

    # Document model
    provider: EmbeddingProvider = EmbeddingProvider.OPENAI
    model: str = "text-embedding-3-small"
    api_key_set: bool = Field(default=False,
        description="Indicator only â€” actual key is in keyring")

    # Query model
    query_model: QueryModelConfig = Field(
        default_factory=QueryModelConfig)

    # Vectorization parameters
    dimensions: int | None = Field(default=None,
        description="Vector dimensions (null = model default)")
    batch_size: int = Field(default=100, ge=1, le=2048)
    normalize: bool = Field(default=True,
        description="L2-normalize vectors")

    # Cache
    cache_enabled: bool = True
    cache_backend: CacheBackend = CacheBackend.DISK

    # Advanced
    timeout: int = Field(default=30, ge=5, le=120)
    max_retries: int = Field(default=3, ge=0, le=10)
    rate_limit_rpm: int = Field(default=3000, ge=0, le=10000)
    truncation: TruncationStrategy = TruncationStrategy.END
```

### 5.2 Gestionnaire de secrets (backend)

```python
# ragkit/security/secrets.py
"""Secure API key management using system keyring with encrypted fallback."""

from __future__ import annotations

import hashlib
import json
import os
import platform
from pathlib import Path

import keyring
from keyring.errors import NoKeyringError

from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64

SERVICE_NAME = "ragkit"
CREDENTIALS_FILE = Path.home() / ".ragkit" / "credentials.enc"


class SecretsManager:
    """Manages API keys securely via keyring or encrypted file fallback."""

    def __init__(self):
        self._keyring_available = self._check_keyring()
        if not self._keyring_available:
            self._fernet = self._init_fernet()

    def _check_keyring(self) -> bool:
        """Check if system keyring is available."""
        try:
            keyring.get_password(SERVICE_NAME, "__test__")
            return True
        except NoKeyringError:
            return False

    def _get_machine_id(self) -> bytes:
        """Derive a machine-specific identifier."""
        info = f"{platform.node()}-{platform.machine()}-{os.getlogin()}"
        return hashlib.sha256(info.encode()).digest()

    def _init_fernet(self) -> Fernet:
        """Initialize Fernet cipher with machine-derived key."""
        salt = b"ragkit-credential-salt-v1"
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=480000,
        )
        key = base64.urlsafe_b64encode(
            kdf.derive(self._get_machine_id()))
        return Fernet(key)

    def store(self, key_name: str, value: str) -> None:
        """Store a secret securely."""
        if self._keyring_available:
            keyring.set_password(SERVICE_NAME, key_name, value)
        else:
            self._store_in_file(key_name, value)

    def retrieve(self, key_name: str) -> str | None:
        """Retrieve a secret."""
        if self._keyring_available:
            return keyring.get_password(SERVICE_NAME, key_name)
        return self._retrieve_from_file(key_name)

    def delete(self, key_name: str) -> None:
        """Delete a secret."""
        if self._keyring_available:
            try:
                keyring.delete_password(SERVICE_NAME, key_name)
            except keyring.errors.PasswordDeleteError:
                pass
        else:
            self._delete_from_file(key_name)

    def exists(self, key_name: str) -> bool:
        """Check if a secret exists."""
        return self.retrieve(key_name) is not None

    # --- Encrypted file fallback ---

    def _load_credentials_file(self) -> dict:
        if not CREDENTIALS_FILE.exists():
            return {}
        encrypted = CREDENTIALS_FILE.read_bytes()
        decrypted = self._fernet.decrypt(encrypted)
        return json.loads(decrypted)

    def _save_credentials_file(self, data: dict) -> None:
        CREDENTIALS_FILE.parent.mkdir(parents=True, exist_ok=True)
        encrypted = self._fernet.encrypt(
            json.dumps(data).encode())
        CREDENTIALS_FILE.write_bytes(encrypted)

    def _store_in_file(self, key_name: str, value: str) -> None:
        data = self._load_credentials_file()
        data[key_name] = value
        self._save_credentials_file(data)

    def _retrieve_from_file(self, key_name: str) -> str | None:
        data = self._load_credentials_file()
        return data.get(key_name)

    def _delete_from_file(self, key_name: str) -> None:
        data = self._load_credentials_file()
        data.pop(key_name, None)
        self._save_credentials_file(data)
```

**Convention de nommage des clÃ©s** :

| Composant | ClÃ© dans keyring | Exemple |
|-----------|-----------------|---------|
| Embedding document | `ragkit.embedding.{provider}.api_key` | `ragkit.embedding.openai.api_key` |
| Embedding requÃªte | `ragkit.embedding.query.{provider}.api_key` | `ragkit.embedding.query.cohere.api_key` |
| Reranking (futur) | `ragkit.rerank.{provider}.api_key` | `ragkit.rerank.cohere.api_key` |
| LLM (futur) | `ragkit.llm.{provider}.api_key` | `ragkit.llm.openai.api_key` |

### 5.3 Moteur d'embedding (backend)

```python
# ragkit/embedding/engine.py
"""Embedding engine â€” dispatches to provider implementations."""

from __future__ import annotations

from abc import ABC, abstractmethod

import numpy as np

from ragkit.config.embedding_schema import EmbeddingConfig, EmbeddingProvider


class BaseEmbeddingProvider(ABC):
    """Abstract base class for all embedding providers."""

    def __init__(self, config: EmbeddingConfig, api_key: str | None = None):
        self.config = config
        self.api_key = api_key

    @abstractmethod
    async def embed_texts(self, texts: list[str]) -> list[list[float]]:
        """Embed a batch of texts and return vectors."""
        ...

    @abstractmethod
    async def embed_query(self, query: str) -> list[float]:
        """Embed a single query text."""
        ...

    @abstractmethod
    async def test_connection(self) -> ConnectionTestResult:
        """Test that the provider is reachable and functional."""
        ...

    @abstractmethod
    def get_model_info(self) -> ModelInfo:
        """Return metadata about the configured model."""
        ...


class OpenAIEmbeddingProvider(BaseEmbeddingProvider):
    """OpenAI embedding API provider."""
    ...


class OllamaEmbeddingProvider(BaseEmbeddingProvider):
    """Ollama local embedding provider."""
    ...


class HuggingFaceEmbeddingProvider(BaseEmbeddingProvider):
    """Local embedding via sentence-transformers or ONNX runtime."""
    ...


class CohereEmbeddingProvider(BaseEmbeddingProvider):
    """Cohere embedding API provider."""
    ...


class VoyageAIEmbeddingProvider(BaseEmbeddingProvider):
    """VoyageAI embedding API provider."""
    ...


class MistralEmbeddingProvider(BaseEmbeddingProvider):
    """Mistral embedding API provider."""
    ...


# Provider registry
PROVIDER_REGISTRY: dict[EmbeddingProvider, type[BaseEmbeddingProvider]] = {
    EmbeddingProvider.OPENAI: OpenAIEmbeddingProvider,
    EmbeddingProvider.OLLAMA: OllamaEmbeddingProvider,
    EmbeddingProvider.HUGGINGFACE: HuggingFaceEmbeddingProvider,
    EmbeddingProvider.COHERE: CohereEmbeddingProvider,
    EmbeddingProvider.VOYAGEAI: VoyageAIEmbeddingProvider,
    EmbeddingProvider.MISTRAL: MistralEmbeddingProvider,
}


def create_embedding_provider(
    config: EmbeddingConfig,
    api_key: str | None = None,
) -> BaseEmbeddingProvider:
    """Factory function to create the appropriate embedding provider."""
    provider_cls = PROVIDER_REGISTRY[config.provider]
    return provider_cls(config, api_key)
```

### 5.4 Cache d'embeddings (backend)

```python
# ragkit/embedding/cache.py
"""Embedding cache with memory and disk backends."""

from __future__ import annotations

import hashlib
import json
import sqlite3
from abc import ABC, abstractmethod
from pathlib import Path

from ragkit.config.embedding_schema import CacheBackend


class BaseEmbeddingCache(ABC):
    """Abstract base class for embedding caches."""

    @abstractmethod
    def get(self, text: str, model_id: str) -> list[float] | None:
        ...

    @abstractmethod
    def put(self, text: str, model_id: str, vector: list[float]) -> None:
        ...

    @abstractmethod
    def clear(self) -> None:
        ...

    @abstractmethod
    def stats(self) -> CacheStats:
        ...

    @staticmethod
    def cache_key(text: str, model_id: str) -> str:
        """Generate a deterministic cache key."""
        content = f"{model_id}::{text}"
        return hashlib.sha256(content.encode()).hexdigest()


class MemoryEmbeddingCache(BaseEmbeddingCache):
    """In-memory embedding cache (dict-based)."""

    def __init__(self):
        self._store: dict[str, list[float]] = {}

    def get(self, text: str, model_id: str) -> list[float] | None:
        return self._store.get(self.cache_key(text, model_id))

    def put(self, text: str, model_id: str, vector: list[float]) -> None:
        self._store[self.cache_key(text, model_id)] = vector

    def clear(self) -> None:
        self._store.clear()

    def stats(self) -> "CacheStats":
        return CacheStats(
            entries=len(self._store),
            size_bytes=0,  # Approximate
        )


class DiskEmbeddingCache(BaseEmbeddingCache):
    """SQLite-backed persistent embedding cache."""

    DB_PATH = Path.home() / ".ragkit" / "cache" / "embeddings.db"

    def __init__(self):
        self.DB_PATH.parent.mkdir(parents=True, exist_ok=True)
        self._conn = sqlite3.connect(str(self.DB_PATH))
        self._conn.execute("""
            CREATE TABLE IF NOT EXISTS embeddings (
                key TEXT PRIMARY KEY,
                model_id TEXT NOT NULL,
                vector BLOB NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

    # ... implementation ...


class CacheStats:
    entries: int
    size_bytes: int
```

### 5.5 API REST (routes backend)

#### 5.5.1 Routes Embedding Config

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/embedding/config` | GET | Config embedding courante | â€” | `EmbeddingConfig` |
| `/api/embedding/config` | PUT | Met Ã  jour la config | `EmbeddingConfig` (partiel) | `EmbeddingConfig` |
| `/api/embedding/config/reset` | POST | RÃ©initialise au profil actif | â€” | `EmbeddingConfig` |

#### 5.5.2 Routes Secrets (clÃ©s API)

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/secrets/store` | POST | Stocke une clÃ© API | `{ key_name: string, value: string }` | `{ success: bool }` |
| `/api/secrets/exists` | POST | VÃ©rifie si une clÃ© existe | `{ key_name: string }` | `{ exists: bool }` |
| `/api/secrets/delete` | POST | Supprime une clÃ© API | `{ key_name: string }` | `{ success: bool }` |

> **Important** : il n'y a **pas** de route `GET` pour rÃ©cupÃ©rer une clÃ© API. La clÃ© n'est jamais transmise au frontend. Le frontend ne connaÃ®t que l'indicateur `api_key_set: true/false`.

#### 5.5.3 Routes Test & Environnement

| Endpoint | MÃ©thode | Description | Corps | RÃ©ponse |
|----------|---------|-------------|-------|---------|
| `/api/embedding/test-connection` | POST | Teste la connexion au provider | `{ provider?, model? }` (optionnel, sinon config courante) | `ConnectionTestResult` |
| `/api/embedding/test-embedding` | POST | Teste l'embedding de deux textes | `{ text_a: string, text_b: string }` | `EmbeddingTestResult` |
| `/api/embedding/environment` | GET | DÃ©tection de l'environnement local | â€” | `EnvironmentInfo` |
| `/api/embedding/models` | GET | Liste les modÃ¨les disponibles pour un provider | `?provider=openai` | `AvailableModelsResponse` |
| `/api/embedding/cache/stats` | GET | Statistiques du cache | â€” | `CacheStats` |
| `/api/embedding/cache/clear` | POST | Vide le cache | â€” | `{ success: bool, entries_cleared: int }` |

#### 5.5.4 ModÃ¨les de rÃ©ponse

```python
class ConnectionTestResult(BaseModel):
    success: bool
    provider: str
    model: str
    dimensions: int | None = None
    latency_ms: int | None = None
    error: str | None = None
    error_code: str | None = None   # "auth_error", "network_error",
                                     # "model_not_found", "timeout"

class EmbeddingTestResult(BaseModel):
    success: bool
    text_a: TextEmbeddingInfo
    text_b: TextEmbeddingInfo
    cosine_similarity: float | None = None
    error: str | None = None

class TextEmbeddingInfo(BaseModel):
    text_preview: str               # TronquÃ© Ã  100 caractÃ¨res
    token_count: int
    dimensions: int
    latency_ms: int

class AvailableModelsResponse(BaseModel):
    provider: str
    models: list[ModelInfo]

class ModelInfo(BaseModel):
    id: str                          # Ex: "text-embedding-3-small"
    display_name: str                # Ex: "Text Embedding 3 Small"
    dimensions: int | list[int]      # Fixe ou variable
    max_tokens: int
    cost_per_million: float | None   # En USD, null pour local
    languages: str                   # "multilingue", "anglais", etc.
    description: str
    local: bool                      # true si exÃ©cutÃ© localement

class EnvironmentInfo(BaseModel):
    gpu_available: bool
    gpu_name: str | None = None
    gpu_backend: str | None = None   # "cuda", "mps", null
    ollama_available: bool
    ollama_version: str | None = None
    ollama_models: list[str] = Field(default_factory=list)
    local_cached_models: list[str] = Field(default_factory=list)
    keyring_available: bool

class CacheStats(BaseModel):
    entries: int
    size_mb: float
    backend: str                     # "memory" or "disk"
    model_id: str | None = None      # ModÃ¨le associÃ© au cache actuel
```

### 5.6 Commandes Tauri (Rust) â€” ajouts

```rust
// desktop/src-tauri/src/commands.rs (ajouts Ã‰tape 3)

// Embedding config
#[tauri::command]
pub async fn get_embedding_config() -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn update_embedding_config(config: serde_json::Value) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn reset_embedding_config() -> Result<serde_json::Value, String> { ... }

// Secrets management
#[tauri::command]
pub async fn store_secret(key_name: String, value: String) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn secret_exists(key_name: String) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn delete_secret(key_name: String) -> Result<serde_json::Value, String> { ... }

// Test & environment
#[tauri::command]
pub async fn test_embedding_connection(
    provider: Option<String>,
    model: Option<String>
) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn test_embedding(text_a: String, text_b: String) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn get_embedding_environment() -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn get_available_models(provider: String) -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn get_embedding_cache_stats() -> Result<serde_json::Value, String> { ... }

#[tauri::command]
pub async fn clear_embedding_cache() -> Result<serde_json::Value, String> { ... }
```

### 5.7 Composants React â€” arborescence

```
desktop/src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â”œâ”€â”€ IngestionSettings.tsx              â† existant (Ã‰tape 1)
â”‚   â”‚   â”œâ”€â”€ ChunkingSettings.tsx               â† existant (Ã‰tape 2)
â”‚   â”‚   â”œâ”€â”€ EmbeddingSettings.tsx              â† NOUVEAU : section complÃ¨te
â”‚   â”‚   â”œâ”€â”€ EnvironmentPanel.tsx               â† NOUVEAU : dÃ©tection GPU/Ollama
â”‚   â”‚   â”œâ”€â”€ ProviderSelector.tsx               â† NOUVEAU : sÃ©lecteur provider + modÃ¨le
â”‚   â”‚   â”œâ”€â”€ ModelInfoCard.tsx                  â† NOUVEAU : fiche descriptive du modÃ¨le
â”‚   â”‚   â”œâ”€â”€ ApiKeyInput.tsx                    â† NOUVEAU : champ clÃ© API sÃ©curisÃ©
â”‚   â”‚   â”œâ”€â”€ QueryModelPanel.tsx                â† NOUVEAU : config modÃ¨le requÃªtes
â”‚   â”‚   â”œâ”€â”€ VectorizationParams.tsx            â† NOUVEAU : dimensions, batch, normalisation
â”‚   â”‚   â”œâ”€â”€ EmbeddingCachePanel.tsx            â† NOUVEAU : config et stats du cache
â”‚   â”‚   â”œâ”€â”€ ConnectionTestButton.tsx           â† NOUVEAU : bouton test connexion
â”‚   â”‚   â””â”€â”€ EmbeddingTestPanel.tsx             â† NOUVEAU : panneau test similaritÃ©
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ SecretInput.tsx                    â† NOUVEAU : input masquÃ© gÃ©nÃ©rique
â”‚       â”œâ”€â”€ StatusIndicator.tsx                â† NOUVEAU : indicateur ğŸŸ¢ğŸŸ¡ğŸ”´âšª
â”‚       â”œâ”€â”€ SimilarityBar.tsx                  â† NOUVEAU : barre de similaritÃ© visuelle
â”‚       â””â”€â”€ ... (existants Ã‰tape 1-2)
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useEmbeddingConfig.ts                  â† NOUVEAU : hook config embedding
â”‚   â”œâ”€â”€ useEnvironment.ts                      â† NOUVEAU : hook dÃ©tection environnement
â”‚   â”œâ”€â”€ useSecrets.ts                          â† NOUVEAU : hook gestion clÃ©s API
â”‚   â”œâ”€â”€ useConnectionTest.ts                   â† NOUVEAU : hook test connexion
â”‚   â””â”€â”€ useEmbeddingTest.ts                    â† NOUVEAU : hook test embedding
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ipc.ts                                 â† MODIFIER : ajouter routes embedding + secrets
â””â”€â”€ locales/
    â”œâ”€â”€ fr.json                                â† MODIFIER : ajouter clÃ©s embedding
    â””â”€â”€ en.json                                â† MODIFIER : ajouter clÃ©s embedding
```

### 5.8 DÃ©tail des composants clÃ©s

#### `ApiKeyInput.tsx`

Composant rÃ©utilisable pour la saisie sÃ©curisÃ©e de clÃ©s API. Sera rÃ©utilisÃ© pour Reranking (Ã‰tape 8) et LLM (Ã‰tape 9).

```tsx
interface ApiKeyInputProps {
  keyName: string;           // ex: "ragkit.embedding.openai.api_key"
  provider: string;          // ex: "openai"
  isSet: boolean;            // true si la clÃ© est dÃ©jÃ  stockÃ©e
  onKeyStored: () => void;   // callback aprÃ¨s sauvegarde
  onKeyDeleted: () => void;  // callback aprÃ¨s suppression
}

export function ApiKeyInput({ keyName, provider, isSet, ...props }: ApiKeyInputProps) {
  const [visible, setVisible] = useState(false);
  const [editing, setEditing] = useState(false);
  const [value, setValue] = useState("");

  // La clÃ© n'est JAMAIS rÃ©cupÃ©rÃ©e du backend pour l'afficher
  // Le frontend connaÃ®t uniquement isSet: true/false

  return (
    <div>
      {isSet && !editing ? (
        <div className="flex items-center gap-2">
          <span className="text-green-600">ğŸŸ¢ ClÃ© configurÃ©e</span>
          <button onClick={() => setEditing(true)}>âœ Modifier</button>
          <button onClick={handleDelete}>ğŸ—‘</button>
        </div>
      ) : (
        <div className="flex items-center gap-2">
          <input
            type={visible ? "text" : "password"}
            value={value}
            onChange={(e) => setValue(e.target.value)}
            placeholder="sk-..."
          />
          <button onClick={() => setVisible(!visible)}>ğŸ‘</button>
          <button onClick={handleSave} disabled={!value}>Sauvegarder</button>
        </div>
      )}
    </div>
  );
}
```

#### `ProviderSelector.tsx`

SÃ©lecteur de provider avec affichage conditionnel de la liste de modÃ¨les et de la fiche descriptive.

```tsx
export function ProviderSelector({
  provider, model, onProviderChange, onModelChange
}: ProviderSelectorProps) {
  const { environment } = useEnvironment();
  const { data: models } = useAvailableModels(provider);

  const providers = [
    { id: "openai", name: "OpenAI", icon: "ğŸŒ", needsKey: true },
    { id: "ollama", name: "Ollama (local)", icon: "ğŸ¦™", needsKey: false,
      disabled: !environment?.ollama_available },
    { id: "huggingface", name: "HuggingFace (local)", icon: "ğŸ¤—", needsKey: false },
    { id: "cohere", name: "Cohere", icon: "ğŸŒ", needsKey: true },
    { id: "voyageai", name: "VoyageAI", icon: "ğŸŒ", needsKey: true },
    { id: "mistral", name: "Mistral", icon: "ğŸŒ", needsKey: true },
  ];

  return (
    <>
      <Select label="Provider" options={providers} value={provider}
              onChange={onProviderChange} />
      <Select label="ModÃ¨le" options={models} value={model}
              onChange={onModelChange} />
      {selectedModel && <ModelInfoCard model={selectedModel} />}
    </>
  );
}
```

### 5.9 Persistance

La config embedding est stockÃ©e dans `settings.json` :

```json
{
  "version": "1.0.0",
  "setup_completed": true,
  "profile": "legal_compliance",
  "calibration_answers": { "...": "..." },
  "ingestion": { "...": "..." },
  "chunking": { "...": "..." },
  "embedding": {
    "provider": "openai",
    "model": "text-embedding-3-small",
    "api_key_set": true,
    "query_model": {
      "same_as_document": true
    },
    "dimensions": null,
    "batch_size": 50,
    "normalize": true,
    "cache_enabled": true,
    "cache_backend": "disk",
    "timeout": 30,
    "max_retries": 3,
    "rate_limit_rpm": 3000,
    "truncation": "end"
  },
  "retrieval": { "...": "valeurs calculÃ©es, utilisÃ©es aux Ã‰tapes 5-7" },
  "rerank": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 8" },
  "llm": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 9" },
  "agents": { "...": "valeurs calculÃ©es, utilisÃ©es Ã  l'Ã‰tape 10" }
}
```

> **Rappel** : `api_key_set: true` est un indicateur. La clÃ© rÃ©elle est dans le keyring systÃ¨me sous `ragkit.embedding.openai.api_key`.

### 5.10 DÃ©pendances Python ajoutÃ©es

```toml
# pyproject.toml â€” ajouts aux dependencies pour Ã‰tape 3
dependencies = [
    # ... (existants Ã‰tapes 0-2)
    "openai>=1.0",                  # Client API OpenAI (embedding)
    "cohere>=5.0",                  # Client API Cohere (embedding)
    "voyageai>=0.2",                # Client API VoyageAI (embedding)
    "mistralai>=0.1",               # Client API Mistral (embedding)
    "httpx>=0.25",                  # Client HTTP async (Ollama)
    "onnxruntime>=1.16",            # InfÃ©rence locale rapide
    "huggingface_hub>=0.20",        # TÃ©lÃ©chargement de modÃ¨les
    "keyring>=24.0",                # Trousseau systÃ¨me natif
    "cryptography>=41.0",           # AES-256 pour credentials (fallback)
    "numpy>=1.24",                  # OpÃ©rations vectorielles (similaritÃ© cosinus)
]
```

> **Note** : `sentence-transformers` (ajoutÃ© Ã  l'Ã‰tape 2 pour le chunking sÃ©mantique) est toujours prÃ©sent. Ã€ l'Ã‰tape 3, il est Ã©galement utilisÃ© comme backend pour le provider `huggingface` si ONNX Runtime n'est pas disponible.

### 5.11 Flux d'exÃ©cution des providers

#### Provider OpenAI

```
1. RÃ©cupÃ©rer la clÃ© API depuis keyring (ragkit.embedding.openai.api_key)
2. Initialiser le client openai.AsyncOpenAI(api_key=...)
3. DÃ©couper les textes en batches de batch_size
4. Pour chaque batch :
   a. Appel openai.embeddings.create(model=..., input=batch, dimensions=...)
   b. Retry avec backoff exponentiel si erreur (max_retries)
   c. Respect du rate_limit_rpm (sleep si nÃ©cessaire)
5. Normaliser les vecteurs si normalize=true
6. Mettre en cache si cache_enabled=true
7. Retourner les vecteurs
```

#### Provider Ollama

```
1. VÃ©rifier qu'Ollama est accessible (http://localhost:11434)
2. Pour chaque texte (Ollama n'a pas de batch natif) :
   a. POST http://localhost:11434/api/embeddings { model: ..., prompt: text }
   b. Extraire le vecteur de la rÃ©ponse
3. Normaliser si nÃ©cessaire
4. Mettre en cache
5. Retourner les vecteurs
```

#### Provider HuggingFace (local)

```
1. VÃ©rifier si le modÃ¨le est en cache (~/.ragkit/models/)
2. Si non : tÃ©lÃ©charger via huggingface_hub.snapshot_download()
3. Charger le modÃ¨le :
   a. PrioritÃ© ONNX Runtime si le modÃ¨le a un fichier .onnx
   b. Sinon sentence-transformers (PyTorch)
4. Encoder les textes en batches
5. Normaliser si nÃ©cessaire
6. Mettre en cache
7. Retourner les vecteurs
```

---

## 6. CritÃ¨res d'acceptation

### 6.1 Fonctionnels

| # | CritÃ¨re |
|---|---------|
| F1 | La section `PARAMÃˆTRES > ParamÃ¨tres avancÃ©s > EMBEDDING` est accessible et affiche tous les paramÃ¨tres |
| F2 | Le panneau "Environnement dÃ©tectÃ©" affiche le statut GPU, Ollama et modÃ¨les locaux |
| F3 | Le sÃ©lecteur de provider propose les 6 providers avec les modÃ¨les associÃ©s |
| F4 | Les providers cloud nÃ©cessitant une clÃ© API affichent le champ de saisie sÃ©curisÃ© |
| F5 | Le champ de clÃ© API est masquÃ© par dÃ©faut et ne rÃ©vÃ¨le jamais la clÃ© stockÃ©e |
| F6 | Le bouton "Tester la connexion" vÃ©rifie l'accessibilitÃ©, l'authentification et le modÃ¨le |
| F7 | Le rÃ©sultat du test affiche le statut (succÃ¨s/erreur), les dimensions et la latence |
| F8 | Le provider Ollama est grisÃ© si Ollama n'est pas dÃ©tectÃ© |
| F9 | La fiche descriptive du modÃ¨le (dimensions, max tokens, coÃ»t, langues) s'affiche sous le sÃ©lecteur |
| F10 | Le panneau "ModÃ¨le de requÃªtes" permet de configurer un modÃ¨le distinct ou d'utiliser le mÃªme |
| F11 | Un avertissement s'affiche si les dimensions du modÃ¨le de requÃªtes diffÃ¨rent du modÃ¨le de documents |
| F12 | Le panneau de test d'embedding calcule et affiche la similaritÃ© cosinus entre deux textes |
| F13 | La barre de similaritÃ© s'affiche avec un code couleur et un qualificatif |
| F14 | Les champs de test sont prÃ©-remplis avec des exemples adaptÃ©s au profil actif |
| F15 | Le cache affiche ses statistiques (entrÃ©es, taille) et peut Ãªtre vidÃ© |
| F16 | Un avertissement s'affiche quand un changement de modÃ¨le invalide le cache |
| F17 | Les paramÃ¨tres avancÃ©s (timeout, retries, rate limit, truncation) sont configurables |
| F18 | Le badge "ModifiÃ©" apparaÃ®t Ã  cÃ´tÃ© de chaque paramÃ¨tre modifiÃ© |
| F19 | Le bouton "RÃ©initialiser au profil" restaure les valeurs par dÃ©faut avec confirmation |
| F20 | Tous les textes sont traduits FR/EN via i18n |

### 6.2 Techniques

| # | CritÃ¨re |
|---|---------|
| T1 | `GET /api/embedding/config` retourne la config embedding courante |
| T2 | `PUT /api/embedding/config` valide et persiste les modifications |
| T3 | `POST /api/embedding/config/reset` restaure les valeurs du profil actif |
| T4 | `POST /api/secrets/store` stocke une clÃ© dans le keyring (ou fichier chiffrÃ© fallback) |
| T5 | `POST /api/secrets/exists` vÃ©rifie l'existence sans retourner la valeur |
| T6 | Aucune route ne retourne la clÃ© API en clair |
| T7 | `POST /api/embedding/test-connection` valide la connexion avec le provider configurÃ© |
| T8 | `POST /api/embedding/test-embedding` retourne les vecteurs et la similaritÃ© cosinus |
| T9 | Le provider OpenAI fonctionne avec `text-embedding-3-small` et une clÃ© valide |
| T10 | Le provider Ollama fonctionne avec un modÃ¨le d'embedding installÃ© localement |
| T11 | Le provider HuggingFace fonctionne avec `all-MiniLM-L6-v2` en local |
| T12 | Le cache disk persiste les embeddings entre redÃ©marrages |
| T13 | Le cache est invalidÃ© automatiquement quand le modÃ¨le change |
| T14 | Le pipeline parsing â†’ chunking â†’ embedding fonctionne de bout en bout |
| T15 | La dÃ©tection de GPU (CUDA/MPS) fonctionne correctement |
| T16 | La dÃ©tection d'Ollama fonctionne (installÃ© et non installÃ©) |
| T17 | La config embedding est persistÃ©e dans `settings.json` sous la clÃ© `embedding` |
| T18 | `tsc --noEmit` ne produit aucune erreur TypeScript |
| T19 | Le CI passe sur les 4 targets (lint + build) |

---

## 7. PÃ©rimÃ¨tre exclus (Ã‰tape 3)

- **Stockage vectoriel** : sera ajoutÃ© Ã  l'Ã‰tape 4.
- **Ingestion complÃ¨te** : le pipeline fonctionne pour les tests mais les vecteurs ne sont pas persistÃ©s dans une BDD vectorielle.
- **ParamÃ¨tres gÃ©nÃ©raux** : restent vides Ã  cette Ã©tape.
- **Chat fonctionnel** : reste un placeholder.
- **Tableau de bord fonctionnel** : reste un placeholder.
- **RÃ©duction de dimensionnalitÃ©** (PCA, UMAP) : prÃ©vue en amÃ©lioration future.
- **Quantification des embeddings** (float16, int8) : prÃ©vue en amÃ©lioration future.
- **Pooling strategy** (mean, max, cls_token) : prÃ©vue en amÃ©lioration future.
- **Gestion complÃ¨te de la sÃ©curitÃ©** (rotation des clÃ©s, audit trail) : sera finalisÃ©e Ã  l'Ã‰tape 12.

---

## 8. Estimation

| TÃ¢che | Effort estimÃ© |
|-------|---------------|
| SchÃ©ma Pydantic embedding + validation | 0.5 jour |
| `SecretsManager` (keyring + fallback chiffrÃ©) | 1.5 jours |
| ImplÃ©mentation `OpenAIEmbeddingProvider` | 1 jour |
| ImplÃ©mentation `OllamaEmbeddingProvider` | 1 jour |
| ImplÃ©mentation `HuggingFaceEmbeddingProvider` (ONNX + sentence-transformers) | 1.5 jours |
| ImplÃ©mentation `CohereEmbeddingProvider` | 0.5 jour |
| ImplÃ©mentation `VoyageAIEmbeddingProvider` | 0.5 jour |
| ImplÃ©mentation `MistralEmbeddingProvider` | 0.5 jour |
| Cache d'embeddings (memory + disk/SQLite) | 1 jour |
| DÃ©tection d'environnement (GPU, Ollama, modÃ¨les locaux) | 0.5 jour |
| Routes API embedding (config CRUD + test + secrets + cache) | 1.5 jours |
| Commandes Tauri (Rust) | 0.5 jour |
| Composant `EmbeddingSettings.tsx` (orchestrateur) | 1 jour |
| Composant `ProviderSelector.tsx` + `ModelInfoCard.tsx` | 1 jour |
| Composant `ApiKeyInput.tsx` (champ sÃ©curisÃ© rÃ©utilisable) | 0.5 jour |
| Composant `EnvironmentPanel.tsx` | 0.5 jour |
| Composant `ConnectionTestButton.tsx` | 0.5 jour |
| Composant `EmbeddingTestPanel.tsx` + `SimilarityBar.tsx` | 1 jour |
| Composant `EmbeddingCachePanel.tsx` | 0.5 jour |
| Composants UI rÃ©utilisables (`SecretInput`, `StatusIndicator`) | 0.5 jour |
| Hooks (`useEmbeddingConfig`, `useSecrets`, `useConnectionTest`, etc.) | 1 jour |
| Traductions i18n (FR + EN) â€” embedding + fiches modÃ¨les | 0.5 jour |
| Tests unitaires providers (6 providers Ã— mock API) | 2 jours |
| Tests SecretsManager (keyring + fallback) | 0.5 jour |
| Tests d'intÃ©gration (pipeline parsing â†’ chunking â†’ embedding) | 1 jour |
| Tests manuels + corrections | 1 jour |
| **Total** | **~21 jours** |
